<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN""http://www.w3.org/TR/html4/loose.dtd">
<HTML
><HEAD
><TITLE
>Tuning Linux</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.79"></HEAD
><BODY
CLASS="BOOK"
BGCOLOR="#FFFFFF"
TEXT="#000000"
LINK="#0000FF"
VLINK="#840084"
ALINK="#0000FF"
><DIV
CLASS="BOOK"
><A
NAME="INDEX"
></A
><DIV
CLASS="TITLEPAGE"
><H1
CLASS="TITLE"
><A
NAME="AEN2"
>Tuning Linux</A
></H1
><H3
CLASS="AUTHOR"
><A
NAME="AEN4"
></A
>Mark Komarinski</H3
><DIV
CLASS="AFFILIATION"
><DIV
CLASS="ADDRESS"
><P
CLASS="ADDRESS"
>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<CODE
CLASS="EMAIL"
>&#60;<A
HREF="mailto:mkomarinski@wayga.org"
>mkomarinski@wayga.org</A
>&#62;</CODE
><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</P
></DIV
></DIV
><H3
CLASS="AUTHOR"
><A
NAME="AEN10"
></A
>Michael C. Jett</H3
><DIV
CLASS="REVHISTORY"
><TABLE
WIDTH="100%"
BORDER="0"
><TR
><TH
ALIGN="LEFT"
VALIGN="TOP"
COLSPAN="3"
><B
>Revision History</B
></TH
></TR
><TR
><TD
ALIGN="LEFT"
>Revision 0.30</TD
><TD
ALIGN="LEFT"
>2001-4-17</TD
><TD
ALIGN="LEFT"
>Revised by: mfk</TD
></TR
><TR
><TD
ALIGN="LEFT"
COLSPAN="3"
>Outline stuff from Michael C. Jett</TD
></TR
><TR
><TD
ALIGN="LEFT"
>Revision 0.20</TD
><TD
ALIGN="LEFT"
>2001-3-27</TD
><TD
ALIGN="LEFT"
>Revised by: mfk</TD
></TR
><TR
><TD
ALIGN="LEFT"
COLSPAN="3"
>Created network and disk chapters.  Need more info!</TD
></TR
><TR
><TD
ALIGN="LEFT"
>Revision 0.10</TD
><TD
ALIGN="LEFT"
>2001-2-28</TD
><TD
ALIGN="LEFT"
>Revised by: mfk</TD
></TR
><TR
><TD
ALIGN="LEFT"
COLSPAN="3"
>Second pass.  Time to add some data.</TD
></TR
><TR
><TD
ALIGN="LEFT"
>Revision 0.01</TD
><TD
ALIGN="LEFT"
>2001-01-25</TD
><TD
ALIGN="LEFT"
>Revised by: mfk</TD
></TR
><TR
><TD
ALIGN="LEFT"
COLSPAN="3"
>First pass for the book.  Define the outline.</TD
></TR
></TABLE
></DIV
><DIV
><DIV
CLASS="ABSTRACT"
><P
></P
><A
NAME="AEN35"
></A
><P
>      This work covers tuning Linux and the hardware it runs on
      for the best efficiency.  This can make existing hardware
      run faster, or give network architechts information to make
      informed decisions about servers and their requirements.
    </P
><P
></P
></DIV
></DIV
><HR></DIV
><DIV
CLASS="TOC"
><DL
><DT
><B
>Table of Contents</B
></DT
><DT
><A
HREF="#FOREWARD"
>Foreward</A
></DT
><DT
><A
HREF="#COPYRIGHT"
>Copyright</A
></DT
><DT
>1. <A
HREF="#INTRO"
>Introduction</A
></DT
><DD
><DL
><DT
>1.1. <A
HREF="#CONVENTIONS"
>Conventions</A
></DT
></DL
></DD
><DT
>2. <A
HREF="#FUNDAMENTALS"
>System Performance Fundamentals</A
></DT
><DD
><DL
><DT
>2.1. <A
HREF="#FUNDAMENTALSCOMPONENTS"
>Viewing a server as a system of components</A
></DT
><DT
>2.2. <A
HREF="#FUNDAMENTALSBOTTLENECKS"
>Bottlenecks and Process Times</A
></DT
><DT
>2.3. <A
HREF="#FUNDAMENTALSUBSYSTEMS"
>Interrelation between subsystems</A
></DT
><DT
>2.4. <A
HREF="#FUNDAMENTALSHOWMUCH"
>How Much Machine is Required?</A
></DT
></DL
></DD
><DT
>3. <A
HREF="#MEASURE"
>Measuring your performance</A
></DT
><DD
><DL
><DT
>3.1. <A
HREF="#MEASUREDRIVE"
>Hard Drive</A
></DT
><DT
>3.2. <A
HREF="#MEASURECPU"
>CPU and System</A
></DT
><DT
>3.3. <A
HREF="#MEASURENETWORK"
>Network</A
></DT
><DT
>3.4. <A
HREF="#MEASUREVIDEO"
>Video card</A
></DT
></DL
></DD
><DT
>4. <A
HREF="#DISK"
>Disk Tuning</A
></DT
><DD
><DL
><DT
>4.1. <A
HREF="#DISKINTRO"
>Introduction to disk tuning</A
></DT
><DT
>4.2. <A
HREF="#DISKOVERVIEW"
>Overview of Disk Technologies</A
></DT
><DT
>4.3. <A
HREF="#DISKTUNING"
>Tuning your drives</A
></DT
></DL
></DD
><DT
>5. <A
HREF="#NETWORK"
>Network Tuning</A
></DT
><DD
><DL
><DT
>5.1. <A
HREF="#NETWORKINTRO"
>Introduction to network tuning</A
></DT
><DT
>5.2. <A
HREF="#NETWORKOVERVIEW"
>Network Technologies Overview</A
></DT
><DT
>5.3. <A
HREF="#NETWORKETHERNET"
>Networking with Ethernet</A
></DT
><DT
>5.4. <A
HREF="#NETWORKTCPIP"
>Tuning TCP/IP performance</A
></DT
><DT
>5.5. <A
HREF="#NETWORKDIALUP"
>Tuning Linux dialup</A
></DT
><DT
>5.6. <A
HREF="#NETWORKWIRELESS"
>Wireless Ethernet</A
></DT
><DT
>5.7. <A
HREF="#NETWORKMONITORING"
>Monitoring Network Performance</A
></DT
></DL
></DD
><DT
>6. <A
HREF="#KERNEL"
>Kernel Tuning</A
></DT
><DD
><DL
><DT
>6.1. <A
HREF="#KERNELVERSIONS"
>Kernel versions</A
></DT
><DT
>6.2. <A
HREF="#KERNELCOMPILE"
>Compiling the Linux Kernel</A
></DT
><DT
>6.3. <A
HREF="#KERNELRUNNING"
>Tuning a Runing Linux System</A
></DT
></DL
></DD
><DT
>7. <A
HREF="#APPS"
>Application Tuning</A
></DT
><DD
><DL
><DT
>7.1. <A
HREF="#APPSSQUID"
>Squid Proxy Server</A
></DT
><DT
>7.2. <A
HREF="#APPSMAIL"
>SMTP and Mail Delivery</A
></DT
><DT
>7.3. <A
HREF="#APPSDATABASE"
>MySQL, PostgresSQL, other databases</A
></DT
><DT
>7.4. <A
HREF="#APPSFIREWALL"
>Routers and firewalls</A
></DT
><DT
>7.5. <A
HREF="#APPSAPACHE"
>Apache web server</A
></DT
><DT
>7.6. <A
HREF="#APPSSAMBA"
>Samba File Sharing</A
></DT
><DT
>7.7. <A
HREF="#APPSNFS"
>Network File System</A
></DT
></DL
></DD
></DL
></DIV
><DIV
CLASS="LOT"
><DL
CLASS="LOT"
><DT
><B
>List of Tables</B
></DT
><DT
>5-1. <A
HREF="#NETWORKETHERNETMII"
><B
CLASS="COMMAND"
>mii-tool</B
> Media Types</A
></DT
><DT
>5-2. <A
HREF="#NETWORKSPEED"
>Settings for <B
CLASS="COMMAND"
>setserial</B
></A
></DT
></DL
></DIV
><DIV
CLASS="LOT"
><DL
CLASS="LOT"
><DT
><B
>List of Figures</B
></DT
><DT
>6-1. <A
HREF="#KERNELMAKEXCONFIG"
><B
CLASS="COMMAND"
>make xconfig</B
></A
></DT
><DT
>6-2. <A
HREF="#KERNELPOWERTWEAK"
>Powertweak</A
></DT
></DL
></DIV
><DIV
CLASS="PREFACE"
><HR><H1
><A
NAME="FOREWARD"
></A
>Foreward</H1
><P
>     The idea of a book on tuning Linux for performance is pretty much
     a moving target.  Linux makes advances at a rapid pace, and things
     change often.  Since its introduction in 1991, Linux has gone
     from a state where it could not compile itself (and barely boot)
     into a system that can take up to three full CD-ROMs to install
     much of the software.  It rivals operating systems twice its
     age in terms of performance and stability.  Its complete
     heritage may never be known because of the thousands of people
     around the world who have contributed patches, drivers, and
     enhancements to make Linux better.
   </P
><P
>     This advancement means that some portions of Linux
     can literally turn on a dime.  The Linux 2.0 kernel used
     a program called ipfwadm to administer its firewall settings.
     When 2.2 came out, the program was ipchains, and used completely
     different concepts than ipfwadm.  The 2.4 kernel uses iptables,
     which itself is different from its predecessors.  This means
     that Linux has little baggage holding it back when it comes
     to backwards compatability.  Some open source applications
     need no changes, most may need to be recompiled, and some
     require programming changes that can be done by any
     programmer.  The idea of backwards compatability in Linux
     is a foreign concept.
   </P
><P
>     But tuning Linux is more than just tuning what you have.  It
     is looking at your requirements, evaluating the technology that
     can solve that requirement, and going with the balance between
     cost and performance.  Not everyone can afford the best cards, but
     the difference between good and poor performance can be a very small
     cost as compared to the overall system cost.
   </P
></DIV
><DIV
CLASS="PREFACE"
><HR><H1
><A
NAME="COPYRIGHT"
></A
>Copyright</H1
><P
>     This document is Copyright (c) 2001-2016 Mark F. Komarinski
     <CODE
CLASS="EMAIL"
>&#60;<A
HREF="mailto:mkomarinski@wayga.org"
>mkomarinski@wayga.org</A
>&#62;</CODE
>.
   </P
><P
>     Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License,
     Version 1.3 or any later version published by the Free Software Foundation; with no Invariant Sections, with no Front-Cover
     Texts, and with no Back-Cover Texts. A copy of the license is available at https://www.gnu.org/licenses/fdl.html.
   </P
></DIV
><DIV
CLASS="CHAPTER"
><HR><H1
><A
NAME="INTRO"
></A
>Chapter 1. Introduction</H1
><P
>    This book is arranged into a few major sections.  This will
    allow you to read the sections of the book that apply to
    the kind of tuning you want to do.
  </P
><P
></P
><UL
><LI
><P
>        Fundamentals
      </P
><A
NAME="AEN59"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
>	  What is the nature of performance tuning?  How should you go about
	  looking at an entire system in terms of improving the services it
	  provides to others?  What common strategies are available?  We will go
	  through the basics of performance tuning in detail for this chapter.
	</P
></BLOCKQUOTE
></LI
><LI
><P
>        Measuring performance
      </P
><A
NAME="AEN63"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
>	  This chapter will deal with measuring performance from a system on
	  various levels, outling common tools bundled with your Linux system or
	  available on the Internet.  Once you know how fast your system is in
	  its current state, you have a baseline to measure against.
	</P
></BLOCKQUOTE
></LI
><LI
><P
>        Disk
      </P
><A
NAME="AEN67"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
>&#13;	  This section will compare various kinds of permanent storage.  We'll
	  take a look at hard drives, how to write to them, and any tradeoffs
	  between reliability and raw speed.

        </P
></BLOCKQUOTE
></LI
><LI
><P
>        Kernel
      </P
><A
NAME="AEN71"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
>          This section will cover some of the popular kernels that
          are available and how you can use the built in tools
          to tune it for maximum performance.  We'll cover things
          like the /proc directory, 
          
          sysctl, and recompiling kernels.
        </P
></BLOCKQUOTE
></LI
><LI
><P
>        Network
      </P
><A
NAME="AEN77"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
>       	There are a variety of networking schemes, and one will fit your need.
        Even once you have chosen your networking method, there are ways of
        enhancing it for even better performance.
        </P
></BLOCKQUOTE
></LI
><LI
><P
>        Applications
      </P
><A
NAME="AEN81"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
>        This section is not strictly about Linux, but poorly
        configured applications can quickly erode any advantages
        from other tuning methods.  We will take a look at
        tuning various web servers, database applications, and
        cluster software.
        </P
></BLOCKQUOTE
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="CONVENTIONS"
>1.1. Conventions</A
></H2
><P
>This book uses the following conventions:
  </P
><DIV
CLASS="INFORMALTABLE"
><P
></P
><A
NAME="AEN88"
></A
><TABLE
BORDER="0"
FRAME="void"
CLASS="CALSTABLE"
><COL><COL><THEAD
><TR
><TH
>Descriptions</TH
><TH
>Appearance</TH
></TR
></THEAD
><TBODY
><TR
><TD
>Warnings</TD
><TD
><DIV
CLASS="CAUTION"
><P
></P
><TABLE
CLASS="CAUTION"
WIDTH="100%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/caution.png"
HSPACE="5"
ALT="Caution"></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
><P
>Warnings.</P
></TD
></TR
></TABLE
></DIV
></TD
></TR
><TR
><TD
>Hint</TD
><TD
><DIV
CLASS="TIP"
><P
></P
><TABLE
CLASS="TIP"
WIDTH="100%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/tip.png"
HSPACE="5"
ALT="Tip"></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
><P
>Hint.</P
></TD
></TR
></TABLE
></DIV
></TD
></TR
><TR
><TD
>Notes</TD
><TD
><DIV
CLASS="NOTE"
><P
></P
><TABLE
CLASS="NOTE"
WIDTH="100%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/note.png"
HSPACE="5"
ALT="Note"></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
><P
>Note.</P
></TD
></TR
></TABLE
></DIV
></TD
></TR
><TR
><TD
>Information requiring special attention</TD
><TD
><DIV
CLASS="WARNING"
><P
></P
><TABLE
CLASS="WARNING"
WIDTH="100%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/warning.png"
HSPACE="5"
ALT="Warning"></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
><P
>Warning.</P
></TD
></TR
></TABLE
></DIV
></TD
></TR
><TR
><TD
>File Names</TD
><TD
><TT
CLASS="FILENAME"
>file.extension</TT
></TD
></TR
><TR
><TD
>Directory Names</TD
><TD
><TT
CLASS="FILENAME"
>directory</TT
></TD
></TR
><TR
><TD
>Commands to be typed</TD
><TD
><B
CLASS="COMMAND"
>command</B
></TD
></TR
><TR
><TD
>Applications Names</TD
><TD
><SPAN
CLASS="APPLICATION"
>application</SPAN
></TD
></TR
><TR
><TD
>Prompt of users command under bash shell</TD
><TD
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>$</PRE
></FONT
></TD
></TR
></TABLE
></TD
></TR
><TR
><TD
>Prompt of root users command under bash shell</TD
><TD
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>#</PRE
></FONT
></TD
></TR
></TABLE
></TD
></TR
><TR
><TD
>Prompt of user command under tcsh shell</TD
><TD
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>tcsh$</PRE
></FONT
></TD
></TR
></TABLE
></TD
></TR
><TR
><TD
>Environment Variables</TD
><TD
><CODE
CLASS="ENVAR"
>VARIABLE</CODE
></TD
></TR
><TR
><TD
>Emphasized word</TD
><TD
><EM
>word</EM
></TD
></TR
><TR
><TD
>Code Example</TD
><TD
><TABLE
BORDER="0"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="PROGRAMLISTING"
><CODE
CLASS="SGMLTAG"
>&#60;para&#62;</CODE
>Beginning and end of paragraph<CODE
CLASS="SGMLTAG"
>&#60;/para&#62;</CODE
></PRE
></FONT
></TD
></TR
></TABLE
></TD
></TR
></TBODY
></TABLE
><P
></P
></DIV
></DIV
></DIV
><DIV
CLASS="CHAPTER"
><HR><H1
><A
NAME="FUNDAMENTALS"
></A
>Chapter 2. System Performance Fundamentals</H1
><P
>    There are a few fundamental concepts important to understanding
    the performance characteristics of a system.  Most of these are
    very obvious, they are just not often thought of when dealing
    with tuning a system.
  </P
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="FUNDAMENTALSCOMPONENTS"
>2.1. Viewing a server as a system of components</A
></H2
><P
>     The first, and most important, concept is looking at a server as a
     system of components.  While you may get tremendous performance
     gains by moving from 7200 RPM to 10,000 RPM drives, you may not.  To
     determine what needs to be done, and what benefit improving a
     particular component will be, you must first lay out the system
     and evaluate each component.
   </P
><P
>     In a typical server sytem the major components are:
   </P
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
>Processor</DT
><DD
><P
>            The processor, or processors, in a system are quite obviously
            the little black chip, or card edge socket, or big card/chip
            and heatsink combination on the motherboard.  But the
            processor subsytem referred to here includes not only the
            processor, but also the L1 and L2 processor caches, the
            system bus, and various motherboard components.
          </P
></DD
><DT
>Physical Disk</DT
><DD
><P
>            The physical disk subsytem includes the disk drive spindles
            themselves, as well as the interface between drive and
            controller/adapter card, the adapter card or cards, and
            the bus interface between controller/adapter card and the
            motherboard.
	  </P
></DD
><DT
>Network</DT
><DD
><P
>	    The definition of the network subsystem varies depending on
            who you ask.  All definitions include the network card and
	    its bus interface, and the physical media it connects to,
	    such as Ethernet.  If you are looking at improving the
	    performance of a server this is all that concerns
            you.  However, in a larger analysis of performance this
	    subsystem may include and number of network links between your
	    server and clients.
	  </P
></DD
><DT
>Memory</DT
><DD
><P
>	    The memory subsystem includes two major types of memory, real
            and virtual.  Real memory is the chip, chips, or cards in the
	    computer that provide physical memory.  Virtual memory includes
	    this memory as well as the virtual memory stored on disk,
            often referred to as a paging file or swap partition.
	  </P
></DD
><DT
>Operating System</DT
><DD
><P
>	    The single most complex component of any system is the
	    operating system.  While there are more opportunities for
	    tuning here, there are also more opportunities to make a
	    simple mistake that will cost you thousands in additional
	    hardware to handle the load.
	  </P
></DD
></DL
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="FUNDAMENTALSBOTTLENECKS"
>2.2. Bottlenecks and Process Times</A
></H2
><P
>      The next concept to understand is the total time through a system
      for one request.  Let's say you want a hamburger from McDonald's.
      You walk in the door and there are four people in line in front
      of you (just like normal).  The person taking and filling orders
      takes care of one person in 2 minutes.  So the person being waited
      on now will be done in 2 minutes, when the next person in line will
      be waited on, which takes 2 minutes.  In all it will be 8 minutes
      before you give the friendly counter person your order, and 10
      minutes total before you get your food.
    </P
><P
>      If we cut the time it takes for the counter person to wait on
      someone from 2 minutes to 1, everything moves faster.  Each person
      takes 1 minute, so you have your order in 5.  But since each person
      is in line a shorter period of time, the probability that there
      will be 4 people in line in front of you decreases as well.  So
      improving processing time of a resource that has a queue waiting
      for it provides a potentially exponential improvement in total time
      through the system.  This is why we address bottlenecked resources
      first.
    </P
><P
>      The reason we say <SPAN
CLASS="QUOTE"
>"potentially exponential"</SPAN
> improvement
      is that the
      actual improvement depends on a number of factors, which are
      discussed further.  Basically, the process time
      is most likely not constant, but depends on many factors, including
      availability of other system resources on which it could be 
      blocked waiting for a response.  In addition, the arrival rate of
      requests is probably not constant, but instead spread on some type
      of distribution.  So if you happen to arrive during a burst of
      customers, like at lunch hour, when the kitchen is backed up getting
      hamburgers out for the drive through, you could still see a 2 minute
      processing time and 4 people in line in front of you.  Actually
      determining the probabilities of these events is an exercise left to
      the reader, as is hitting yourself in the head with a brick.
      The idea here is just to introduce you to the concepts so you
      understand why your system performs as it does.
    </P
><P
>      Another concept in high performance computing is parallel computing,
      used for applications like Beowulf.
      If your application is written correctly, this is like walking into
      McDonalds and seeing 4 people in line, but there are 4 lines 
      open.  So you can walk right up to a counter
      and get your burger in about two minutes.  The down side of this is
      that the manager of the store has to pay for more people working in
      the store, or you have to buy more machines.
      There are also potential bottlenecks, such as only one
      person in the back making fries, or the person in line in front of
      you is still trying to decide what they want.
    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="FUNDAMENTALSUBSYSTEMS"
>2.3. Interrelation between subsystems</A
></H2
><P
>      The last concept to cover here is the interrelation between
      subsystems on the total systems performance.  If a system is
      short on memory, it will page excessively.  This will put
      additional load on the drive subsystem.  While tuning the drive
      subsystem will definitely help, the better answer is to add more
      memory.
    </P
><P
>      As another example, your system may be performing just fine except
      for the network connection, which is 10Base-T.  When you upgrade
      the network card to 100Base-T, performance improves only marginally.
      Why?  It could very well be that the network was the bottleneck, but
      removing that bottleneck immediately revealed a bottleneck on the disk
      system.
    </P
><P
>      This makes it very important that you accurately measure where
      the bottleneck is.  It can not only improve the time it takes
      you to speed up the system, but also save money, since you
      only need to upgrade one subsystem instead of many. 
    </P
><P
>      The best way to find out the interrelations depends on the application
      you are using.  As we go through various subsystems and applications
      in this book, you will have to keep this in mind.  For example, the
      Squid web cache has heavy memory and disk requirements.  Using less
      memory will increase the disk usage, and decrease performance.  By
      looking at memory usage, you can see that memory is being swapped to
      the hard drive.  Increasing the available memory so that no more swapping
      of squid will be your best performance bet.
    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="FUNDAMENTALSHOWMUCH"
>2.4. How Much Machine is Required?</A
></H2
><P
>      A frequent question when deciding to buy new hardware is "How much
      hardware should be purchased for the task?".  A good rule of thumb is "as
      much as you can afford", but that may not be the whole answer.  You should
      consider the following when defining specifications.
    </P
><P
></P
><UL
><LI
><P
>	  If you cannot afford a fully loaded system, can it be expanded after
	  purchase?  If you application would work best with 2GB of RAM, but you
	  can only afford 1GB, can the motherboard be expanded to add the extra
	  GB later on?  Purchasing a motherboard that can only accept 1GB means
	  you will need to buy a new motherboard (at least) later on, increasing
	  cost.
	</P
></LI
><LI
><P
>	  How well does the design scale?  If you plan on buying racks of
	  machines, can you add new racks later and integrate them easily with
	  the existing system?  Things like switches that can accept new blades
	  to add functionality may save space and money in the long run, while
	  reducing issues like cabling.
	</P
></LI
><LI
><P
>	  How easy is it to install, upgrade, or repair?  While using desktop
	  systems in a rack is possible and will save money, replacing or
	  repairing the systems is harder to do.  A good question to ask
	  yourself is "What is my time worth?".
	</P
></LI
></UL
></DIV
></DIV
><DIV
CLASS="CHAPTER"
><HR><H1
><A
NAME="MEASURE"
></A
>Chapter 3. Measuring your performance</H1
><P
>    In order to see if your system is any faster, you need to measure
    the performance of the system before and after you try your tuning
    changes.  There's a variety of applications for testing your hard drive,
    CPU, memory, and overall system performance.  This allows you to also test a
    proposed configuration versus the existing configuration.
  </P
><P
>    In all cases of testing, you should have a relatively quiet system, meaning
    that there is a minimum of applications running.  For true testing, you
    should reboot the machine between each test, and run each test at least
    5 times, then take the average.  Rebooting clears any in-memory caches that
    can affect the tuning numbers, and also makes sure there is a larger amount
    of system RAM free.
  </P
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="MEASUREDRIVE"
>3.1. Hard Drive</A
></H2
><P
>      The easiest way to find raw hard drive performance is using
      <B
CLASS="COMMAND"
>hdparm</B
>, which we describe in <A
HREF="#DISKTUNINGIDEOS"
>Section 4.3.1.2</A
>.  But this is raw hard drive performance, not
      taking into account things like overhead from the filesystem or write
      performance.
    </P
><P
>      The other application you can use to test how the filesystem works, or for
      devices that do not work with <B
CLASS="COMMAND"
>hdparm</B
> is to use
      <B
CLASS="COMMAND"
>dd</B
>.  The <B
CLASS="COMMAND"
>dd</B
> command is used to write
      or read data and perform some conversion along the way.  The nice part of
      the command for us is that it can create a file of any size containing
      ASCII NULL (0), which allows us to test consistently.
      Since the data we want to write is being generated in the CPU and memory
      which is always faster than the hard drive, this gives a good look at the
      disk bottleneck.
    </P
><P
>      This is used in conjunction with <B
CLASS="COMMAND"
>time</B
> which gives
      the amount of CPU, system, and user (real) time used to run a particular
      command.  You can then divide out the size of the file created by the
      number of user seconds to run the command to get a Mbps rating.
    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="MEASURECPU"
>3.2. CPU and System</A
></H2
><P
>      Since CPUs have a variety of functions crammed into a small space, it is
      hard to test how fast a particular CPU is.  A standard number for Linux is
      called <SPAN
CLASS="QUOTE"
>"BogoMIPS"</SPAN
>, which Linus needed for some timing
      routines in the kernel.  BogoMIPS calculate how fast a CPU can do nothing,
      and so will vary depending on the kind of chip used.  Because of how
      BogoMIPS are calculated, they should not be used for any form of
      performance measurement.
    </P
><P
>      There are a variety of CPU functions that can be measured, including
      Million Instructions Per Second (MIPS), Floating Point Operations Per
      Second (FLOPS), and memory to CPU speed (in MBps).  Each of these will
      vary greatly depending on the choice of CPU.  MIPS are almost worthless,
      since some chips can have one instruction that runs multiple other
      instructions.  The MMX instruction set for Intel-based hardware is a good
      example for this, as MMX is set to perform matrix operations from just a
      few instructions, whereas without MMX, it would take many more operations
      to do the same calulations.  When measuring chip speed, does an MMX
      instruction count as one or multiple instructions?  Since the speed of
      running one MMX instruction is slightly faster than running the multiple
      instructions that make it up, it will make an MMX-based chip appear
      slower.
    </P
><P
>      Many online reviewers use games as a measurement of the CPU.  The idea is
      that 3D games provide a good stress test of the CPU, memory interface,
      system bus, and video card.  The result is the number of Frames Per Second
      (FPS).  More FPS means a faster overall system.  Since most servers do not
      have a 3D card in them, this may not be a good choice of measurement.
      Workstations may get a benefit from this kind of testing, however.
    </P
><P
>      One other measurement form is that of other third-party applications.
      Applications like SETI@Home, distributed.net can give generic speed
      ratings that are good to compare against other machines running the same
      software.  Other CPU-intensive applications like MP3 encoders can also be
      a good guide of how fast a CPU is.  The down side to these are that the
      results have to be compared to the results of other machines running the
      exact same software.  If the software is not available for that
      OS/Hardware combination, the test is worthless.
    </P
><P
>      So what does this leave us with?  Unfortunately, not a lot.  The best bet
      appears to be MIPS and FLOPS, since it does test instructions per second,
      and as
      long as the chipset remains the same (Intel based, SPARC, Alpha, etc.),
      the
      measurements can be compared pretty easily and the comparisons will be
      close enough.
    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="MEASURENETWORK"
>3.3. Network</A
></H2
><P
>      Measuring the network speed is not quite easy, since there are bottlenecks
      outside the network interface and your machine.  Cable problems, poor
      choice of switching gear, and congestion on the line or the remote machine
      you want to test against can all reduce the throughput of your network
      interface.  In addition, protocols like SSH or HTTP have additional
      processing that may need to be done that occupies the CPU and reduces
      throughput.
    </P
><P
>      If the machine you are testing is going to be a server, you can create a
      small group of client machines on a private network.  These machines
      should have the same type of network card and OS revision.  This will
      create a stable baseline of testing.
    </P
><P
>      Depending on the networking application you will be using, there may be
      applications that already exist to automate this testing for you.
      Programs like <SPAN
CLASS="APPLICATION"
>webbench</SPAN
> can coordinate the
      clients talking to the server, and be able to read the performance of the
      server in terms of pages per second.
    </P
><P
>    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="MEASUREVIDEO"
>3.4. Video card</A
></H2
><P
>      If you want to tune a workstation, or create a killer Quake III box, you
      will want to pay attention to the video subsystem and see how well it
      performs.  For 2D applications, you can test the system using
      <B
CLASS="COMMAND"
>x11perf</B
>.  This program will perform a variety of tests
      using the X server and drivers.  Since it is designed for performance
      testing, it is designed to run each test five times, then take the
      average.  The machine should have no other users or activity going on, and
      you should disable the screen saver.  You can disable the screensaver
      either with the command <B
CLASS="COMMAND"
>xset s off</B
> or by killing the
      process called <SPAN
CLASS="QUOTE"
>"xscreensaver"</SPAN
>.  You may need to run both
      commands in order to turn off the screen saver.
    </P
><P
>      Testing with <B
CLASS="COMMAND"
>x11perf</B
> will take several hours depending
      on the speed of your CPU and graphics card.  Once complete, you will have
      a log file that you can then compare against other machines that have also
      done testing, or against a baseline test you ran before tuning to see if
      the X server speed has been improved.  To do this comparison, you can use
      <B
CLASS="COMMAND"
>x11perfcomp</B
> to compare two or more tests.  Higher
      numbers are better, as the resulting numbers are in terms of objects per
      second.
    </P
><P
>      You can test out 3D performance using applications like Quake III, that
      run the application through a set world and events, most of which will
      stress the system.  Mark down the resolution, bit depth, and frames per
      second reported from Quake III, and you now have a baseline to work from.
    </P
><P
>      A caveat to using Quake or 3D applications is that this is testing more
      than the video card.  Other subsystems, like the CPU, video drivers, GLX
      (3D) drivers, and memory are also tested.  If you want to use this method
      for comparing speed, you should also be sure the other subsystems are
      tuned as well.
    </P
></DIV
></DIV
><DIV
CLASS="CHAPTER"
><HR><H1
><A
NAME="DISK"
></A
>Chapter 4. Disk Tuning</H1
><DIV
CLASS="SECTION"
><H2
CLASS="SECTION"
><A
NAME="DISKINTRO"
>4.1. Introduction to disk tuning</A
></H2
><P
>      Your drive system is one of the places where bottlenecks can
      occur.  All of your database information, boot code, swap
      space, and user programs live on the hard drives.  Hard drives
      are speeding up, now topping 15,000 RPM and bus rates
      of over 160MB per second.  Even at these speeds, drives are still
      much slower than RAM or your CPU, with requests to drives waiting
      for the drive to spin to the right location, read and/or write
      the data that is required, and send the answer back to the CPU.
    </P
><P
>      To top this off, hard drives are one of the moving parts in your
      machine, and moving parts are more likely to fail over time than
      a solid state mechanism, like your memory or CPU.  One of the
      reasons why power supplies have such low MTBFs is the fan
      that keeps the power supply cool has a low MTBF.  Once the
      fan dies, it's only a matter of time before the power supply
      itself overheats and dies.  Some systems overcome this
      by installing multiple power supplies, so if one dies, the
      others can take over.  Fortunately for hard drives, this
      failover is available in the form of RAID (Redundant Array
      of Inexpensive Disks).
    </P
><P
>      Then there are questions about the cost of differing systems
      versus their performance versus other options.  We will take
      a look at these options throughout this chapter, starting
      with an overview of existing hard drive technology for Linux.
    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="DISKOVERVIEW"
>4.2. Overview of Disk Technologies</A
></H2
><P
>      
      
      There are, as you may know, two major hard disk technologies
      that work under Linux: Integrated Drive Electronics (IDE), and Small
      Computer System Interface (SCSI).  At the lowest level, IDE and
      SCSI drives share enough technology that IDE and SCSI drives
      are exactly the same save for a PCB board and physical interface
      on the disk itself.  That PCB and phyiscal interface can command
      a premium in price on drive.
    </P
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="DISKOVERVIEWSCSI"
>4.2.1. SCSI drives</A
></H3
><P
>        The history of SCSI drives starts not with large servers
        running multibillion dollar companies, but as its name
        implies, with small systems.  SCSI had one of its first
        implementation on the Apple Macintosh Plus systems.
        SCSI was made to be a general purpose interface, supporting
        not only hard drives, but scanners, CD-ROMs, serial ports,
        and other devices off of one common bus.  Cables were
        inexpensive, the protocol was relatively open, and was
        fast for its time, reaching a maximum of 4MB per second.
      </P
><P
>        SCSI was picked up by server vendors, such as
        Sun and IBM, since it created a common way for servers
        to share devices.  Its advantages in design made it very
        well suited to have multiple devices on the same bus
        with little contention between devices.  Unlike IDE, when
        a SCSI controller makes a request, the drive drops its
        hold on the line, fetches the information, and then
        picks up the line and sends the response.  This allows the
        CPU to continue working on other tasks, so it is not I/O
        bound waiting for the drive.  Other devices on the SCSI bus
        can communicate during this time.  Another advantage to SCSI
        is that you can have multiple SCSI controllers on the
        same bus.  This allows two or more machines to access a single
	SCSI bus and drives that are on that bus.
      </P
><P
>        The increased performance of SCSI and low quantity of
        SCSI drives being made as compared to IDE drives has caused
        an increase in price of SCSI drives.  In many cases, this
        can be almost double the price. But if you need the performance,
        the cost is worth it.
      </P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="DISKOVERVIEWIDE"
>4.2.2. IDE drives</A
></H3
><P
>        SCSI drives are actually stupid.  They rely on a controller
        chip to tell them what to do.  In many cases, a SCSI drive
        used by one SCSI controller cannot be moved to another
        controller and expect to keep all the data safe, since
        each controller has its own way of formatting data on
        the drive.  IDE drives contain most of the brains on the
        drive itself.  This makes it easier for system vendors
        to add support into their systems, reducing cost.  These
        days, most systems will integrate serial ports, IDE, and
        USB all in one chip.  SCSI still requires a (large) dedicated
        chip on the system to work.
      </P
><P
>        The lower cost of parts and higher volume of IDE has made it
        very low cost for most single user systems while retaining
        some of the higher performance of SCSI.  But many of the
        features of SCSI are not available in IDE:  external boxes,
	hot swapping,
        and devices like scanners.  In addition, when an IDE drive
        is asked to do something, that IDE bus is locked while
        the drive processes the request.  IDE devices are usually limited
        to two devices per bus, but can have multiple busses per system.
	Most motherboards come with two IDE busses standard.
      </P
><P
>        Burst performance of IDE drives gets close to that of SCSI,
        but will really only be seen on single user systems such
        as personal workstations.
      </P
><P
>        In the past few years, IDE has had trouble with the existing
        x86 BIOS and larger capacity IDE drives.  Since the BIOS
        has only a limited amount of space to store drive information,
        no way for supporting very large drives was almost impossible
        without modifying the BIOS itself, which would cause headaches
        for do-it-yourself system builders.  Until 2000, Linux would
        not boot on partitions that were larger than 1GB.  Fortunately,
        more recent BIOSes are smart enough to work around these
        size limitations, and Linux has found a way around its
        booting issues.
      </P
><P
>        The future of IDE includes more of the existing ATA/66 and ATA/100
	standards, which provide 66 Mbit and 100 Mbit burst speeds,
	repspectively.  Also upcoming is Serial ATA, which uses a lower
	number of connectors and boosts speed rates to over 1Gbps.
      </P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="DISKWHATTOCHOOSE"
>4.2.3. What Interface Should You Use?</A
></H3
><P
>        Based on the way that IDE and SCSI differ, you should take
        performance into mind when choosing a hard drive bus
        for your systems.  A machine that is part of a cluster
        that relies on network storage can use the less expensive
        IDE drives, since the drive will not be a bottleneck.  A
        machine that will be used as the network storage device
        should have the faster SCSI interface.
      </P
><P
>        There are plenty of grey areas between these two extremes.
        But you should ask yourself a few questions while deciding:
      </P
><P
></P
><UL
><LI
><P
>            Will there be more than one drive in the system?
          </P
></LI
></UL
><P
></P
><UL
><LI
><P
>            Will the hard drive interface be a bottleneck
            on the system?
          </P
></LI
></UL
><P
></P
><UL
><LI
><P
>            Can the system the drives will be installed in
            support the bus I intend to use?
          </P
></LI
></UL
><P
>        Considering the answers to these questions will get you
        a long way to answering what bus you want to use.
      </P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="DISKTUNING"
>4.3. Tuning your drives</A
></H2
><P
>      Now that we understand the major types of drives available
      for your system, let's take a look at the ways you can
      tune your particular setup.
    </P
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="DISKTUNINGIDE"
>4.3.1. Tuning the IDE bus</A
></H3
><P
>        There are a few methods of tuning the IDE bus, both through
        the BIOS setup, and within Linux.  Some of these options
        are not supported by all controllers and all drives, so you
        will want to compare specifications of each before testing.
        As always, be aware that some tuning commands can cause
        data loss, so be sure to back up your data before experimenting.
      </P
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="DISKTUNINGIDEBIOS"
>4.3.1.1. Tuning IDE from within the BIOS</A
></H4
><P
>          Typically, most users will just leave the BIOS to automatically
          configure itself based off a negotiation between the hard drive
          and the controller in the system.  There are, however, a few
          options within the BIOS that users can examine to get either
          improved performance, or debug tricky issues.
        </P
><P
>          There are three methods for IDE to address a drive:  Normal,
          CHS, and LBA.  Normal mode works only with drives smaller
          than 500MB.  Since no drives since 1996 have been made this
          small, we can forget this mode.  CHS stands for Cylinder,
          Head, and Sector, while LBA stands for Logical Block Address.
          CHS and LBA are fairly similar in performance, but be aware
          that taking a drive that is configured in CHS and moving it
          to a system that use LBA will destroy all the data on that
          drive.
        </P
><P
>	  
          Now that the drive can be accessed, there are two methods
          for that drive to get its data from the drive to the CPU:
          PIO, and DMA.  PIO requires the CPU to shuttle data from 
          the drive to memory so the CPU can use it later, but
          is the most compatible way for Linux to talk to a drive
          due to the large number of IDE controller chips.
          DMA mode seems to be much faster, since the CPU is not
          involved in moving the data between the drive and memory,
          freeing the CPU to do other things.  Until the later
          Linux 2.2 kernels, DMA mode was not selected by default
          for access to drives due to compatability with interface
          chips.  You can now select a specific IDE controller and
          select DMA access to make sure your combination is
          correct.
        </P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="DISKTUNINGIDEOS"
>4.3.1.2. Tuning IDE from within Linux</A
></H4
><P
>          As mentioned in <A
HREF="#DISKTUNINGIDEBIOS"
>Section 4.3.1.1</A
>,
          Linux has drivers for some specific IDE controllers,
          plus a generic IDE interface.  Once the OS boots, Linux
          will ignore the state of the BIOS when it accesses hardware,
          choosing instead to use its own drivers and options. By default,
          the Linux kernel will have DMA access available, but not
          activated.  This can be changed if you choose to compile your
          own kernel (see <A
HREF="#KERNELCOMPILE"
>Section 6.2</A
> for more
          information).
        </P
><P
>	  
          Once Linux is started, all IDE tuning occurs using
          <B
CLASS="COMMAND"
>hdparm</B
>.  Using <B
CLASS="COMMAND"
>hdparm</B
>
          followed by a drive (<B
CLASS="COMMAND"
>hdparm /dev/hda</B
>) will
          return the current settings for that drive.
        </P
><P
><B
CLASS="COMMAND"
>hdparm</B
>  [-c <TT
CLASS="REPLACEABLE"
><I
>iovalue</I
></TT
>] [-d] [-m <TT
CLASS="REPLACEABLE"
><I
>multimode</I
></TT
>] {<TT
CLASS="REPLACEABLE"
><I
>device</I
></TT
>}</P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
># hdparm /dev/hda

/dev/hda:
multcount    =  0 (off)
I/O support  =  0 (default 16-bit)
unmaskirq    =  0 (off)
using_dma    =  1 (on)
keepsettings =  0 (off)
nowerr       =  0 (off)
readonly     =  0 (off)
readahead    =  8 (on)
geometry     = 1559/240/63, sectors = 23572080, start = 0
#</PRE
></FONT
></TD
></TR
></TABLE
><P
>          As you can see, there are a few options for tuning that
          are available for this drive.  The biggest boost for IDE drive
	  performance is to use DMA access, and this is already turned
	  on.  If DMA access is not turned on by default in the kernel,
	  you can use -d1 to turn DMA access on, and -d0 to turn it off.
	  Note that DMA access will not necessarily increase performance
	  of getting data to and from the drive, but will free up the CPU
	  during data transfers.
        </P
><P
>          Another item to take a look at is the I/O support, which
          on our sample drive is set to 16-bit access instead of 32.
          The -c option to <B
CLASS="COMMAND"
>hdparm</B
> will check the
          I/O support for the specified device, there are a total of three
          options that can be given to -c to set the I/O support.  The
          two most stable for systems are 0, used to set 16-bit access,
          and 3, used to set 32-bit synchronous access.  Using an
	  <TT
CLASS="REPLACEABLE"
><I
>iovalue</I
></TT
> of 
          1 sets 32-bit access but may not work on all chipsets, causing
          a system hang if the chipset does not support regular 32-bit
          access.
        </P
><P
>          Also test and check out multiple sector I/O with the -m option.
          Many newer IDE drives support transferrint multiple sectors
          worth of data per I/O cycle, reducing the numer of I/O cycles
          required to tranfer data.  The -i option to hdparm will tell
          you what the maximum <TT
CLASS="REPLACEABLE"
><I
>multimode</I
></TT
>
	  is in the MaxMultSect
          section.  By setting <TT
CLASS="REPLACEABLE"
><I
>multimode</I
></TT
>
	  to its highest,
          large transfers of data happen even quicker.
        </P
><DIV
CLASS="WARNING"
><P
></P
><TABLE
CLASS="WARNING"
WIDTH="100%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/warning.png"
HSPACE="5"
ALT="Warning"></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
><P
>            The <B
CLASS="COMMAND"
>hdparm</B
> manual page indicates that
            with some drives, using multiple sector I/O can result
            in massive filsystem corruption.  As always, be sure
            to test your systems thoroughly before using them
            in a production environment.
          </P
></TD
></TR
></TABLE
></DIV
><P
>          Unfortunately, the correct setting for DMA, multiple sector
          I/O, and I/O support varies by drive and controller.  You will
          have to do your own testing to find the correct combination
          for your system.  The right combination should be able to:
        </P
><P
></P
><UL
><LI
><P
>              Have a high throughput of data from the drive to the system.
            </P
></LI
><LI
><P
>              Maintain that high throughput under heavy CPU load.
            </P
></LI
><LI
><P
>              Prevent the drive or the IDE driver from corrupting data.
            </P
></LI
></UL
><P
>          Fortunately, testing throughput is easy with <B
CLASS="COMMAND"
>          hdparm</B
>.  The -t option tests the throughput
          of data directly from the drive, while -T tests throughput
          of data directly from the Linux drive buffer.  To ensure the
          tests run properly, they should be run when the
          system is quiet and few other processes are running.  Usually,
          runlevel 1, also known as single user mode, provides
          this environment.  Tests should be run two or three times.
        </P
><P
>          Once an optimum setting is found, you can have hdparm make
          the setting at boot time by including the relevant commands
          in <TT
CLASS="FILENAME"
>/etc/rc.local</TT
>
        </P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="DISKTUNINGSCSI"
>4.3.2. Tuning SCSI disks</A
></H3
><P
>      </P
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="DISKTUNINGSCSIOPTIONS"
>4.3.2.1. SCSI Options</A
></H4
><P
>	  In many cases, SCSI support is an add-in card to the
	  system, giving you many options in vendors and card
	  types.  Some server motherboards include SCSI chipset
	  and support onboard as well.  In addition, there are
	  dedicated RAID cards that implement various RAID levels
	  in hardware, offloading much of the logic from the CPU.
	</P
><P
>	  SCSI has three major protocol varieties:  SCSI-1, SCSI-2,
	  and SCSI-3.  Fortunately, the protocols are backwards and
	  forwards compatible, meaning that a SCSI-3 controller card
	  can talk to a SCSI-1 drive, albeit at a slower speed.  For
	  best performance, make sure that the protocols of the controller
	  card and devices match.
	</P
><P
>	  On the physical side, cable types range from a DB-25 pin connector
	  on older Apple Macintoshes to 80-pin SCA connectors that not
	  only include the SCSI pins, but power and ID information.
	</P
><P
>	  Here's a quick rundown on the various connector types available.
	</P
><P
>	  INSERT TABLE OF CONNECTORS
	</P
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="DISKTUNINGSCSIRAID"
>4.3.2.1.1. SCSI RAID</A
></H5
><P
>	    
	    Depending on the RAID level you select, you can optimize
	    a drive array ranging from high performance to high availability.
	    In addition, many hardware RAID cards support standby drives,
	    so if one drive in the RAID fails, a previously-unused drive
	    immediately fills in and  becomes part of the RAID.
	  </P
><P
>	    RAID 0 is also known as striping, where each drive in the array
	    is represented together as one large drive.  It is very high
	    I/O performance, since data is written sequentially across
	    each drive.  In RAID 0, no data space is lost, but if one
	    of the drives dies, the entire array is lost.  Drives
	    in the array can be of varying sizes.
	  </P
><P
>	    RAID 1 is known as mirroring.  Each drive mirrors its contents
	    to another drive in the array.  Performance is no slower than
	    and drive in the array, but if one drive in the array fails
	    its mirror immediately takes over with no loss.  RAID 1 has
	    the highest overhead of drive space, requiring two drives
	    for the storage of one.  Each drive pair must be the
	    same size.
	  </P
><P
>	    RAID 5 is one of the most popular RAID formats.  In this 
	    setup, data is spread amongst at least three drives along
	    with parity data.  In the event of any one drive failing, the
	    remaining drives still have all the data from all drives and
	    can continue without loss of data.  If a second drive were
	    to fail, the entire array would fail.  Drive space loss comes
	    to N-1 where N is the number of drives in the array.  So
	    in a 5 drive array, you would get the storage of 4 drives.
	    All drives in this array must be the same size.
	    Since parity data has to be created and written across multiple
	    drives, the speed of RAID 5 is slow, but its reliability is
	    quite high.  For those implementing high availablity on
	    their own, this is the best balance of speed and reliability.
	  </P
><P
>	    There are other RAID levels available, and in some cases
	    these are vendor-specific (such as RAID 51, which is
	    a mirrored RAID 5 array).  For best file performance,
	    RAID 0 will be the fastest.  Configuration of each of
	    these levels usually happens outside of Linux, in the card's
	    BIOS, and is specific to each hardware RAID card.
	  </P
><P
>	    For performance reasons, it is not recommended that you
	    use software RAID.  Instead of offloading the RAID functionality
	    to a hardware card and offload the functions from the CPU, software
	    RAID uses the main CPU to create and maintain the RAID.  This
	    eats up valuable I/O cycles.
	  </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="DISKTUNINGSCSIHW"
>4.3.2.1.2. Tuning SCSI Drives</A
></H5
><P
>	    Since SCSI drivers are written to negotiate the best connection
	    between SCSI controller and its drives, there is very little
	    from the OS that is needed to improve your performance.  Your
	    best idea for performance is to have the latest kernel and drivers
	    and to use the correct driver for your card.  In some cases, there
	    are both Linux and BSD versions of drivers for your card.  Some
	    report that the BSD drivers are faster, so if you have both
	    drivers available, test each out to see which gives better
	    performance.
	  </P
><P
>	    On the hardware side, make sure that you are using the best
	    match of SCSI controller and drives.  Your best performance
	    will probably be seen with Fibre Channel controllers and
	    drives, since they have the highest throughput.  If
	    you have a large number of drives, you can span them across
	    multiple controllers.  Linux supports up to 8 or 16 cards
	    each with the ability to hold up to 16 devices per card,
	    not counting the card itself.
	  </P
><P
>	    One way of tuning the SCSI bus is to make sure it is properly
	    terminated.  Without proper termination, the SCSI bus may ratchet
	    its speed down, or fail altogether.  Termination should occur at
	    both ends of a physical SCSI chain, but most SCSI chipsets include
	    internal termination for their end.  Purchase the correct
	    termination for your cable and put it at the far end of the cable.
	    This will make sure there is no signal reflections anywhere in the
	    cable that can cause interference.
	  </P
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="DISKFILESYSTEMS"
>4.3.3. Tuning Filesystems</A
></H3
><P
>        Fast hard drive access is only half of getting fast read
	and write access.  The other half is getting the data from
	the hard drive, through kernel, and to the application.
	This is the function of the filesystem that the data lives on.
      </P
><P
>        The first Linux filesystems (xiafs, minixfs, extfs) were
	all designed to give some level of performance to Linux
	while giving features close to what you would expect
	from a regular UNIX operating system.  Over time,
	second extended filesystem (ext2fs) arrived and was the
	standard filesystem for Linux for many years.  Now, the number
	of native filesystems for Linux include ext3, reiserfs,
	GFS, Coda, XFS, JFS, and Intermezzo.
      </P
><P
>        Such features that are available for Linux include inodes,
	directories, files, and tools
	to modify and create the filesystem.  Inodes are the basic
	building blocks of the filesystem, creating pointers to
	file data, entries in directories, and directories themselves.
	The directory of inodes is kept in the superblock, and these
	superblocks are duplicated many times through the filesystem
	so if one superblock gets corrupted, another can be used to
	recover the missing data.
      </P
><P
>        In the event the OS shuts down without unmounting its filesystems,
	a filesystem check must be run in order to make sure the
	inodes point to the data it should be pointing at.  A journalling
	filesystem (ext3, reiserfs, JFS, XFS) ensures that all writes
	to a filesystem are
	finished before reporting success to the OS.
      </P
><P
>        Each type of filesystem has its advantages and disadvantages.  A
	filesystem like ext2 or ext3 are better tuned to large files, so access
	for reads and writes happen very quickly.  But if there are a large
	amount of small files in a directory, its performance starts to suffer.
	A filesystem like reiserfs is better tunes to smaller files, but
	increases overhead for larger files.
      </P
><P
>        For applications that are writing or reading the hard drive, block sizes
	will allow Linux to write larger blocks of data to the hard drive in one
	operation.  For example, a block size of 64k will try to write to the
	hard drive in 64kb chunks.  Depending on the hard drive and interface,
	larger block results in better performance.  If the block size is not
	set properly, it can result in poorer performance.  If the optimal block
	size is 64k, but is set for 32k, it would take two operations to write
	the block to the hard drive.  If it is set to 96kb, then it would take
	OS will wait for a timeout period or the rest of the block size to fill
	up before it writes the data to disk, dropping the latency of writing
	data to the disk.
      </P
><P
>        Block sizes are usually reserved for operations where raw data is being
	written to or read from the hard drive.  But applications like
	<SPAN
CLASS="APPLICATION"
>dd</SPAN
> can use varying size block sizes when
	writing data to the drive, allowing you to tune various block sizes.
      </P
></DIV
></DIV
></DIV
><DIV
CLASS="CHAPTER"
><HR><H1
><A
NAME="NETWORK"
></A
>Chapter 5. Network Tuning</H1
><DIV
CLASS="SECTION"
><H2
CLASS="SECTION"
><A
NAME="NETWORKINTRO"
>5.1. Introduction to network tuning</A
></H2
><P
>      Mosix, Beowulf, and other clustering technologies for Linux
      all depend on an effective network layer.  Any delays in getting
      data from the application to the physical layer would cause
      even greater delays in the time to complete the task.  Much work
      has been done to the Linux network stack to reduce this time,
      known as latency, and increase the amount of data that can
      be sent over a period of time, known as bandwidth.
    </P
><P
>      Latency is important as under high loads, the delay of getting
      data through the network layer will slow down the number of requests
      that can be handled at once.  Bandwidth is important since you want
      services like NFS to be able to saturate its network link with data.
      This means that should all the services of a file server be needed,
      it can be provided to as many clients as request it.
    </P
><P
>      This chapter will start with an explination of the available networking
      technologies, then get into how some of these technologies can be
      tuned for both latency and bandwidth improvements.  We will then
      take a look at some of the standard TCP/IP applications and some
      tuning hints or gotchas.
    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="NETWORKOVERVIEW"
>5.2. Network Technologies Overview</A
></H2
><P
>      As is the case in every other section of this book, the faster
      or better the technology, the more expensive it is.  But this
      should not stop you from cobbling together older technology to
      make it a bit better than it is at face value.
    </P
><P
>      The first example of this is Beowulf.  The original design goal
      of Beowulf was to take existing, low cost technology and create
      a supercomputer out of it.  To do this, machines were networked
      together using Ethernet running at 10 megabit.  Since this is
      too slow to have good communication between the nodes, the team
      did something different - bonded two 10 megabit cards together
      to create one 20 megabit connection.  This can be done in software, and
      doubled the performance of a system that would have cost too much
      to upgrade to 100 megabit connection per machine.
    </P
><P
>      These days, 100 megabit connections are standard for most machines,
      with the cost of these cards being under $75US per card.  Much like
      the cards of a few years ago had faster counterparts, so do today's
      cards.  Gigabit Ethernet over copper or fiber is available for those
      who want to spend a few hundred dollars.  If you want to get really
      outrageous and spend a few thousand dollars, you can get a proprietary,
      high speed (2GB), low latency network technology called Myrinet.
      Myrinet is really designed for clusters, mostly due to the high cost
      per server, and dropping down from this networking technology to
      standard Ethernet would lose many of the Myrinet advantages.
    </P
><P
>      Standard Ethernet works with a card, a hub, switch or router, and a
      cable to connect it all together.  The card acts as an interface
      between the system and the Ethernet bus, and there are a variety of 
      cards available, each with varying interface chips, memory, boot roms,
      and prices.  To explain the difference between hubs, switches, and
      routers, we have to take a look at Ethernet, TCP/IP, and layering.
    </P
><P
>      When a packet of data leaves a web server to talk to the web browser,
      it is a TCP/IP packet.  That TCP/IP packet is encapsulated within
      an Ethernet packet.  An Ethernet packet is destined only for the local
      network, and the TCP/IP packet will be re-encapsulated if it has
      to go on another network.  The TCP/IP packet contains the source
      and destination TCP/IP addresses for the packet, while the Ethernet
      packet contains the source and destination addresses for only the
      local network.
    </P
><P
>      A hub is an unintelligent device in that if one port of the hub
      gets a packet, all other ports on the hub will receive that 
      packet.  Due to this, most hubs are very inexpensive, but have
      poor performance, especially as the load increases.
      A switch, on the other hand, knows what Ethernet devices
      exist on each port and can quickly route Ethernet traffic between
      ports.  If a packet comes in on port one, and the switch knows the
      packet is destined to a machine on port twelve, the switch will
      send the packet only to port twelve.  None of the other ports
      will see the packet.  As a result, the cost for a switch is higher,
      but allows greater bandwidth for devices connected to the switch.
    </P
><P
>      Both hubs and switches work on the Ethernet layer, so they only
      look at the Ethernet wrapper for the packet and work only on
      packets that are in the local network.  When you want to connect two
      networks together, or connect to the Internet, you require a router.
      The router opens the Ethernet envelope, then takes a look at the
      source and destination of the TCP/IP packet and sends the packet to
      the appropriate interface.  The nice thing about routers is that
      the interfaces on it does not have to be Ethernet.  Many routers
      combine an Ethernet port and T1 CSU/DSU, or Ethernet and Fiber,
      and so on.  The router re-addresses the TCP/IP packet to go from
      one phyical media to another.  Routers usually have to have a good
      bit of brains in them to handle the packet re-writing, dynamic
      routing, and also requires things like SNMP management and
      some interface for the user to talk to it.  Thus, routers will be
      more expensive than hubs or switches.  Linux can act as a router
      as well, also tying in technologies like IP Masquerading
      and packet filtering.  In some cases, a dedicated Linux box can
      perform routing less expensively than a standalone router, since
      most of the <SPAN
CLASS="QUOTE"
>"brains"</SPAN
> of being a router is already in Linux.
    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="NETWORKETHERNET"
>5.3. Networking with Ethernet</A
></H2
><P
>      Ethernet is the standard networking environment for Linux.  It
      was one of the first to be implemented in Linux, the other being
      AX.25 (Ham Radio networking).  Ethernet has been a standard
      for over twenty years, and the protocol is fairly easy to implement,
      interface cards are inexpensive, cabling is easy to do, and the
      other glue (hubs and switches) that holds the network together
      is also inexpensive.
    </P
><P
>      Linux can run a number of protocols natively over Ethernet,
      including SMB, TCP/IP, AppleTalk, and DECnet.  By far the most popular is
      TCP/IP, since that is the standard protocol for UNIX machines and
      the Internet.
    </P
><P
>      Tuning Ethernet to work with your particular hardware, as always,
      depends on the interface cards, cabling options, and switching gear
      you use.  Many of the tools that Linux uses are standard across most
      networking equipment.  Most cards available today for Linux are
      PCI-based, so configuration of cards through setting IRQ and base
      addresses is not required - the driver will probe and use the
      configuration set by the motherboard.  If you do need to force IRQ or io
      settings, you can do that when loading the module or booting the system
      by passing the arguments irq=x and io=y.
    </P
><P
>      Most of tuning Ethernet for Linux is to get the best physical connection
      between the interface card and the switching gear.  Best performance
      comes from a switch, and switches have a few extra tricks up their
      sleeve.  One of these is full and half duplexing.  In a half-duplex
      setup, the card talks to the switch, then the switch talks to the card,
      and so on.  Only one of the two ends can be talking at the same time.
      In full duplex mode, both card and switch can have data on the wire at
      the same time.  Since there's different lines for transmit and receive
      in Ethernet, there's less congestion on the wire.  This is a great
      solution for high bandwidth devices that have a lot of data coming
      in and out, such as a file server, since it can be sending files while
      receiving requests.
    </P
><P
>      Normally, the Ethernet card and switching gear negotiate a connection
      speed and duplex option using MII, the Media Independent Interface.
      Forcing a change can be used for debugging
      issues, or for getting higher performance.  The
      <B
CLASS="COMMAND"
>mii-tool</B
> utility can show or set the speed and
      duplexing options for your Ethernet links.
    </P
><P
><B
CLASS="COMMAND"
>mii-tool</B
>  [-v, --verbose] [-V, --version] [-R, --reset] [-r, --restart] [-w, --watch] [-l, --log] [-A, --advertise=<TT
CLASS="REPLACEABLE"
><I
>media</I
></TT
>] [-F, --force=<TT
CLASS="REPLACEABLE"
><I
>media</I
></TT
>] [<TT
CLASS="REPLACEABLE"
><I
>interface</I
></TT
>]</P
><DIV
CLASS="TABLE"
><A
NAME="NETWORKETHERNETMII"
></A
><P
><B
>Table 5-1. <B
CLASS="COMMAND"
>mii-tool</B
> Media Types</B
></P
><TABLE
BORDER="1"
CLASS="CALSTABLE"
><COL><COL><COL><COL><COL><THEAD
><TR
><TH
>	      <TT
CLASS="REPLACEABLE"
><I
>media</I
></TT
>
	    </TH
><TH
>	      100Mbit
	    </TH
><TH
>	      10Mbit
	    </TH
><TH
>	      Full Duplex
	    </TH
><TH
>	      Half Duplex
	    </TH
></TR
></THEAD
><TBODY
><TR
><TD
>	      100baseTx-HD
	    </TD
><TD
>	      X
	    </TD
><TD
>&nbsp;</TD
><TD
>&nbsp;</TD
><TD
>	      X
	    </TD
></TR
><TR
><TD
>	      100baseTx-FD
	    </TD
><TD
>	      X
	    </TD
><TD
>&nbsp;</TD
><TD
>	      X
	    </TD
><TD
>&nbsp;</TD
></TR
><TR
><TD
>	      10baseT-HD
	    </TD
><TD
>&nbsp;</TD
><TD
>	      X
	    </TD
><TD
>&nbsp;</TD
><TD
>	      X
	    </TD
></TR
><TR
><TD
>	      10baseT-FD
	    </TD
><TD
>&nbsp;</TD
><TD
>	      X
	    </TD
><TD
>	      X
	    </TD
><TD
>&nbsp;</TD
></TR
></TBODY
></TABLE
></DIV
><DIV
CLASS="NOTE"
><P
></P
><TABLE
CLASS="NOTE"
WIDTH="100%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/note.png"
HSPACE="5"
ALT="Note"></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
><P
>        Also available is <SPAN
CLASS="QUOTE"
>"100baseT4"</SPAN
>, which is an earlier
	form of 100Mbit that uses four pairs of wires whereas
	100BaseTx uses two pairs of wires.
	This protocol is not available for most modern Ethernet cards.
      </P
></TD
></TR
></TABLE
></DIV
><P
>      The most common use of <B
CLASS="COMMAND"
>mii-tool</B
> is to change the
      setting of the media interface from half to full duplex.  Most
      non-intelligent hubs and switches will try to negotiate half duplex
      by default, and intelligent switches can be set to negotiate full duplex
      through some configuration options.
    </P
><P
>      To set an already-existing connection to 100 Mbit, full duplex:
    </P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
># mii-tool -F 100baseTx-FD eth0
# mii-tool eth0
eth0: 100 Mbit, full duplex, link ok
#</PRE
></FONT
></TD
></TR
></TABLE
><P
>      Another way of doing this is to advertise 100 Mbit, full duplex and
      100 Mbit, half duplex:
    </P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
># mii-tool -A 100baseTx-FD,100baseTx-HD eth0
restarting autonegotiation...
#</PRE
></FONT
></TD
></TR
></TABLE
><P
>      Using autonegotiation will not work with many non-intelligent devices
      and will cause you to drop back to 100baseTx-HD (half duplex).  Use
      force when the gear you are talking to is not managed, and use
      autonegotiate if the gear is managed.
    </P
><DIV
CLASS="NOTE"
><P
></P
><TABLE
CLASS="NOTE"
WIDTH="100%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/note.png"
HSPACE="5"
ALT="Note"></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
><P
>        This program only works with chipsets and drivers that support MII.  The
	Intel eepro100 cards implement this, but others may not.  If your driver
	does not support MII, you may need to force the setting at boot time
	when the driver is loaded.
      </P
></TD
></TR
></TABLE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="NETWORKTCPIP"
>5.4. Tuning TCP/IP performance</A
></H2
><P
>      Setting the Maximum Transmission Unit (<ACRONYM
CLASS="ACRONYM"
>MTU</ACRONYM
>) of a
      network interface can be used to tune performance over a TCP/IP link.  The
      MTU is used to set the maximum size of a packet that goes out on
      the wire.  If data is set to go out that is larger than the MTU, the
      packet is broken up into smaller packets.  This can take up some
      processing time to create the Ethernet packets, and decreases bandwidth.
      Ethernet has a set number of bytes it adds on to a packet, no matter
      the size.  Larger packets will have a smaller percentage of overhead
      used up by the Ethernet header.  On the other hand, smaller packets
      is better for latency, since TCP/IP will wait for the MTU to be filled,
      or a timeout to occur before sending a packet of data.  In the event
      of an interactive TCP/IP connection (such as telnet or ssh), the
      user does not want to wait long for their packet to make it from
      their machine to the remote machine.  Smaller MTUs make sure
      the packet size is met earlier and the packet goes out quickly.
    </P
><P
>      In addition, MTUs also have to fit into the size of the medium the
      packet is running over.  Ethernet has a maximum packet size of
      ??WHATISIT??, counting the Ethernet header packets.  Asynchronous
      Transfer Mode, or <ACRONYM
CLASS="ACRONYM"
>ATM</ACRONYM
>, has a very small MTU,
      on the order of a few bytes.  By default, Ethernet TCP/IP connections
      have a MTU of 1500 bytes.  The MTU can be set using
      <B
CLASS="COMMAND"
>ifconfig</B
>:
    </P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
># ifconfig eth0 mtu 1500</PRE
></FONT
></TD
></TR
></TABLE
><P
>      It is recommended to leave the MTU at the maximum number, since almost
      all non-interactive TCP/IP applications will transfer more than 1500
      bytes per session, and a bit of latency for interactive applications
      is more an annoyance than an actual performance bottleneck.
    </P
><P
>      When using Domain Name Servers (<ACRONYM
CLASS="ACRONYM"
>DNS</ACRONYM
>), you may
      run into cases where DNS resolution is a performance bottleneck.  We
      will get into this more in <A
HREF="#APPSAPACHE"
>Section 7.5</A
>, but
      some applications recommend for best performance to log the
      raw TCP/IP addresses that come in and do not try to resolve it to
      a name.  For security reasons, you may want to change this so you can
      quickly find out what machine is trying to break into your web server.
      This decision is left to you, the administrator, as part of the
      never-ending balance between performance and security.  A potential fix
      for this is to run a caching name server locally to store often-used
      TCP/IP addresses and name, and leave the real DNS serving to another
      machine.
    </P
><P
>      Applications like <B
CLASS="COMMAND"
>ping</B
> will sometimes appear to fail
      if DNS is not configured properly, even if you try to ping a TCP/IP
      address instead of using the name.  The solution to this and
      other TCP/IP management applications, is to find the option that
      prevents resolution of names or TCP/IP addresses.  For
      <B
CLASS="COMMAND"
>ping</B
>, this is to give the -n option.
    </P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
># ping -n 192.168.1.50</PRE
></FONT
></TD
></TR
></TABLE
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="NETWORKDIALUP"
>5.5. Tuning Linux dialup</A
></H2
><P
>      If your connection to the rest of the world is through a dialup link,
      don't worry.  <A
HREF="#NETWORKTCPIP"
>Section 5.4</A
> covers many of
      the issues that you will see for dialup.  The MTU for PPP is
      recommended at 1500, but slower links may want an MTU of 296
      to have improved latency.
    </P
><P
>      Modems in Linux should be full fledged modems, not ones labeled
      WinModem or Soft Modems.  Each of these styles of modem pass much
      of the processing work off to the CPU.  This makes the cards very
      inexpensive, but increases the load on the CPU.  Modems can be
      internal or external, but internal modems include their own port
      settings that may be easier to use than with external modems,
      since the modem and serial port are in the same card.  If you use
      external modems, set the data link between the serial port and the modem
      to be the highest the modem supports, which is usually 115,200bps
      or 230,400bps.  This ensures that the modem can talk as fast as it needs
      to with the machine.  You should also ensure that you are using RTS/CTS
      handshaking, also known as hardware, or out-of-band flow control.  This
      allows a modem to immediately tell Linux to stop sending data to the
      modem, preventing loss of data.
    </P
><P
>      Controlling the Linux serial port is used with the
      <B
CLASS="COMMAND"
>setserial</B
> command.  You can find the available
      serial ports at bootup, or by looking at
      <TT
CLASS="FILENAME"
>/proc/tty/driver/serial</TT
>.  Entries in that
      file that have a UART listed exist in Linux.  Remember that COM1
      or Serial 1 listed on your box will be listed as
      <TT
CLASS="FILENAME"
>/dev/ttyS0</TT
>, and COM2 is
      <TT
CLASS="FILENAME"
>/dev/ttyS1</TT
>.  Most modern applications can
      comprehend speeds greater than 38,400bps, but some older ones do not.
      To compensate for this, Linux has made 38,400bps (or 38.4kbps) a
      <SPAN
CLASS="QUOTE"
>"magic"</SPAN
> speed, and if an application asks for 38.4kbps,
      Linux will translate this to another speed.  Currently, this can be
      as high as 460kbps.  To use this, the <B
CLASS="COMMAND"
>setserial</B
>
      command is used.
    </P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
># setserial /dev/ttyS0
/dev/ttyS0, UART: 16550A, Port: 0x03f8, IRQ: 4
# setserial /dev/ttyS0 spd_vhi
# setserial /dev/ttyS0
/dev/ttyS0, UART: 16550A, Port: 0x03f8, IRQ: 4, Flags: spd_vhi</PRE
></FONT
></TD
></TR
></TABLE
><P
>      Speeds are listed as codes for setserial, and these codes are listed
      in <A
HREF="#NETWORKSPEED"
>Table 5-2</A
>.  These values can be set by
      non-root users.
    </P
><DIV
CLASS="TABLE"
><A
NAME="NETWORKSPEED"
></A
><P
><B
>Table 5-2. Settings for <B
CLASS="COMMAND"
>setserial</B
></B
></P
><TABLE
BORDER="1"
CLASS="CALSTABLE"
><COL><COL><THEAD
><TR
><TH
>Code</TH
><TH
>Speed</TH
></TR
></THEAD
><TBODY
><TR
><TD
>spd_normal</TD
><TD
>38.4kbps</TD
></TR
><TR
><TD
>spd_hi</TD
><TD
>57.6kbps</TD
></TR
><TR
><TD
>spd_vhi</TD
><TD
>115.2kbps</TD
></TR
><TR
><TD
>spd_shi</TD
><TD
>230.4kbps</TD
></TR
><TR
><TD
>spd_warp</TD
><TD
>460.8kbps</TD
></TR
></TBODY
></TABLE
></DIV
><P
>      There is also a spd_cust entry that can use a custom speed instead
      of 38.4kbps.  The resulting speed becomes the value of baud_base
      divided by the value of divisor.
    </P
><P
>      If both sides have it available, compression using Deflate or BSD
      is available and can increse throughput.  Even though many newer
      modem protocols provide compression, it isn't very strong.  By using
      Deflate or BSD, greater compression at little loss of CPU or memory
      space can be attained.  The down side is that both sides need to have
      either Deflate or BSD compression available built into the PPP software.
      BSD compression can be activated by using the <CODE
CLASS="OPTION"
>bsdcomp</CODE
>
      option passed to <B
CLASS="COMMAND"
>pppd</B
> followed by a compression
      level between 9 and 15.  Higher numbers indicate higher compression.
      Deflate compression can be used with the <CODE
CLASS="OPTION"
>deflate</CODE
>
      option followed by a number in the range of 8 to 15.  Deflate
      is preferred by the pppd used by Linux.
    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="NETWORKWIRELESS"
>5.6. Wireless Ethernet</A
></H2
><P
>      Wireless Ethernet, also known as IEEE 802.11b, is becoming more 
      popular as the cost to implement decreases and availability of
      more products increase.  The Apple AirPort and Lucent Orinoco cards
      have brought wireless into the home market, allowing a person to
      have Ethernet access anywhere in their house, and schools
      are deploying Wireless Ethernet across the campus.  It's now available
      at airports, schools, many high tech companies, and soon upscale
      coffee shops.
    </P
><P
>      Given that 802.11b is most popular for laptops, since they are portable,
      tuning for performance is not as great importance as tuning for power
      usage.  Using 802.11b is often very power-consuming and can quickly
      drain the batteries.  Some cards (such as the Lucent Orinoco card)
      have the ability to turn its antenna on and off at regular
      intervals.  Instead of the antenna being on all the time, it turns
      on a few times a second.  With the transmitter being turned off
      now more than half the time, the battery usage is decreased.  There is
      an increase of latency and decrease in data rate.
    </P
><P
>      To set the power management of the card, you will need to have the
      wireless tools, available with many distributions.  This package contains
      three commands for managing your wireless card: iwconfig, iwspy, and
      iwpriv.
    </P
><P
>      The <B
CLASS="COMMAND"
>iwconfig</B
> is an extension of
      <B
CLASS="COMMAND"
>ifconfig</B
>.  Run without any options, it will check all
      available interfaces and checks for wireless extensions.  If there are
      any, it will report similar to the following:
    </P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>wvlan0    IEEE 802.11-DS  ESSID:"default"  Nickname:"HERMES I"
          Frequency:2.437GHz  Sensitivity:1/3  Mode:Managed  
          Access Point: 00:90:4B:08:13:1C
          Bit Rate:2Mb/s   RTS thr:off   Fragment thr:off   
          Power Management:off
          Link quality:8/92  Signal level:-88 dBm  Noise level:-96 dBm
          Rx invalid nwid:0  invalid crypt:0 invalid misc:599</PRE
></FONT
></TD
></TR
></TABLE
><P
>      As you can see, the output tells you a variety of statistics on the link.
      My current bit rate is 2Mb/s, probably because my link quality is so low.
      The link quality is 8 out of 92, indicating that I should either move my
      laptop, move my base statiopn, or throw out my 2.4Ghz phone.
    </P
><P
>      You can also see that power management is currently off.  Since my
      laptop is plugged into the wall, this is not a concern to me.  If
      I did want to activate the power management, I would use:
    </P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
># iwconfig wvlan0 power 1
# iwconfig
iwconfig
lo        no wireless extensions.

wvlan0    IEEE 802.11-DS  ESSID:"default"  Nickname:"HERMES I"
          Frequency:2.437GHz  Sensitivity:1/3  Mode:Managed  
          Access Point: 00:90:4B:08:13:1C
          Bit Rate:2Mb/s   RTS thr:off   Fragment thr:off   
          Encryption key:off
          Power Management period:1s   mode:All packets received
          Link quality:11/92  Signal level:-84 dBm  Noise level:-95 dBm
          Rx invalid nwid:0  invalid crypt:0  invalid misc:0
#</PRE
></FONT
></TD
></TR
></TABLE
><P
>      The power management is now set to turn the transmitter on
      only once per second.  By default, the time is in seconds, but
      but appending m or u to the end of the number will make it milliseconds
      or microseconds.
    </P
><P
>      All that being said, here are a few ways in improve the link quality
      of your system.  Any combination of these will work, so do not expect
      one method alone to work.
    </P
><P
></P
><UL
><LI
><P
>	  Check the infrastructure and building materials.  Thick wood or metal
	  walls will cause a lot of interference.  Line of sight to the base
	  station is best.
	</P
></LI
><LI
><P
>	  Some base stations and wireless cards support external antennas.
	  They will greatly
	  improve the range and quality of the link.
	</P
></LI
><LI
><P
>	  Move the base station around.  Line of sight is best, but not
	  required.
	</P
></LI
><LI
><P
>	  Turn off other devices that use 2.4Ghz.  Some phones and other
	  wireless gadgets use the same frequency, and if not built properly,
	  will cause the wireless Ethernet cards to continually scan through
	  frequencies for the correct one, dropping performance.
	</P
></LI
></UL
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="NETWORKMONITORING"
>5.7. Monitoring Network Performance</A
></H2
><P
>      The best way to make sure your network is not the bottleneck
      is to monitor how much traffic is flowing.  Because of collision
      detection and avoidance in Ethernet, once the load gets above
      about 50% to 60% of its maximum, you will start to see degrading 
      performance
      if using hubs.  This number if higher for switches, but still exists
      since the silicon on the switch needs to analyze and move the data
      around.
    </P
><P
>      To make best use of your networking equipment, you will want to
      monitor the amount of traffic that is flowing through the network.
      The easiest way to do this is to use <ACRONYM
CLASS="ACRONYM"
>SNMP</ACRONYM
>,
      or Simple Network Management Protocol.  SNMP was designed to manage
      and monitor machines via the network, be it servers, desktops, or
      other network devices such as switches or network storage.  As you
      would guess, there are SNMP clients and servers avilable for Linux
      to monitor the statistics and usage of network interfaces.
    </P
><P
>      SNMP uses an <ACRONYM
CLASS="ACRONYM"
>MIB</ACRONYM
> or Management Information 
      Base to keep track of the features of an SNMP device.  While
      a Linux box can have things like monitoring the number of
      users logged in, a Cisco router will not need these functions.
      So the MIBs are used to identify devices and their particular
      features.
    </P
><P
>      The SNMP daemon for Linux is net-snmp, formerly known as usd-snmp,
      and based on the cmu SNMP package.  Your distribution should 
      be mostly configured.  The only thing you need to do is set
      the community name, which is really just the password to access
      the snmpd server.  By default, the community name is
      <SPAN
CLASS="QUOTE"
>"private"</SPAN
>, but should be changed to something else.
      You will also want to change the security such that you have readonly
      access to <SPAN
CLASS="APPLICATION"
>snmpd</SPAN
>.
    </P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>#        sec.name  source          community
com2sec  paranoid  default         public
#com2sec readonly  default         public
#com2sec readwrite default         private</PRE
></FONT
></TD
></TR
></TABLE
><P
>      Change the <SPAN
CLASS="QUOTE"
>"paranoid"</SPAN
> above to read <SPAN
CLASS="QUOTE"
>"readonly"</SPAN
>
      and restart <SPAN
CLASS="APPLICATION"
>snmpd</SPAN
>.
    </P
><DIV
CLASS="NOTE"
><P
></P
><TABLE
CLASS="NOTE"
WIDTH="100%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/note.png"
HSPACE="5"
ALT="Note"></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
><P
>        This setting will give readonly access to the entire world to your
	SNMP server.  While a malicious intruder will not be able to change
	data on your machine, it can give them plenty of information about
	your box to find a weakness and exploit it.  You can change the
	<SPAN
CLASS="QUOTE"
>"source"</SPAN
> entry to a machine name, a network address.
	Default means any machine can access <SPAN
CLASS="APPLICATION"
>snmpd</SPAN
>.
      </P
></TD
></TR
></TABLE
></DIV
><P
>      You can test that <SPAN
CLASS="APPLICATION"
>snmpd</SPAN
> is working
      properly by using <B
CLASS="COMMAND"
>snmpwalk</B
> to
      query <B
CLASS="COMMAND"
>snmpd</B
>.
    </P
><P
><B
CLASS="COMMAND"
>snmpwalk</B
>  {<TT
CLASS="REPLACEABLE"
><I
>host</I
></TT
>} {<TT
CLASS="REPLACEABLE"
><I
>community</I
></TT
>} [<TT
CLASS="REPLACEABLE"
><I
>start point</I
></TT
>]</P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>$ snmpwalk 192.168.1.175 public system.sysDescr.0
system.sysDescr.0 = Linux clint 2.2.18 #1 Mon Dec 18 11:23:05 EST 2000 i686
$</PRE
></FONT
></TD
></TR
></TABLE
><P
>      Since this example uses system.sysDescr.0 as its start point, there is
      only one entry that gets listed, that of the output of
      <B
CLASS="COMMAND"
>uname</B
>.
    </P
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="NETWORKMONITORINGMRTG"
>5.7.1. Network Monitoring with MRTG</A
></H3
><P
>        The most popular application for monitoring network traffic is <A
HREF="http://www.mrtg.org/"
TARGET="_top"
>MRTG</A
>, the Multi Router Traffic
	Grapher.
        MRTG tracks and graphs network usage in graphs ranging from the last 24
        hours to a year, all on a web page.  MRTG uses SNMP to fetch information
        from routers.  You can also track individual servers for ingoing and
        outgoing traffic.
      </P
><DIV
CLASS="NOTE"
><P
></P
><TABLE
CLASS="NOTE"
WIDTH="100%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/note.png"
HSPACE="5"
ALT="Note"></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
><P
>          The process of monitoring a server using SNMP will consume a small
          portion of network, memory, and CPU.
        </P
></TD
></TR
></TABLE
></DIV
><P
>        MRTG is available for Red Hat and Debian distributions.  You can also
        download the source from the MRTG home page.  Once installed, you
        will need to configure MRTG to point to the servers or routers you wish
        to monitor.  You can do this with <B
CLASS="COMMAND"
>cfgmaker</B
>.
        The options to cfgmaker have to include the machine and community name
	that you want to monitor.
      </P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>mkomarinski@clint:~$ cfgmaker public@localhost
--base: Get Device Info on public@localhost
--base: Vendor Id: 
--base: Populating confcache
--base: Get Interface Info
--base: Walking ifIndex
--base: Walking ifType
--base: Walking ifSpeed
--base: Walking ifAdminStatus
--base: Walking ifOperStatus
# Created by 
# /usr/bin/cfgmaker public@localhost


### Global Config Options

#  for Debian
WorkDir: /var/www/mrtg

#  or for NT
# WorkDir: c:\mrtgdata

### Global Defaults

#  to get bits instead of bytes and graphs growing to the right
# Options[_]: growright, bits


######################################################################
# System: clint
# Description: Linux clint 2.2.18 #1 Mon Dec 18 11:23:05 EST 2000 i686
# Contact: mkomarinski@valinux.com
# Location: Laptop (various locations)
######################################################################
### Interface 3 &#62;&#62; Descr: 'wvlan0' | Name: '' | Ip: '192.168.1.175' | Eth:
'00-02-2d-08-ae-c1' ###

Target[localhost_3]: 3:public@localhost
MaxBytes[localhost_3]: 1250000
Title[localhost_3]: Traffic Analysis for 3 -- clint
PageTop[localhost_3]: &#60;H1&#62;Traffic Analysis for 3 -- clint&#60;/H1&#62;
 &#60;TABLE&#62;
   &#60;TR&#62;&#60;TD&#62;System:&#60;/TD&#62;     &#60;TD&#62;clint in Laptop (various
locations)&#60;/TD&#62;&#60;/TR&#62;
   &#60;TR&#62;&#60;TD&#62;Maintainer:&#60;/TD&#62;
&#60;TD&#62;mkomarinski@valinux.com&#60;/TD&#62;&#60;/TR&#62;
   &#60;TR&#62;&#60;TD&#62;Description:&#60;/TD&#62;&#60;TD&#62;wvlan0
&#60;/TD&#62;&#60;/TR&#62;
   &#60;TR&#62;&#60;TD&#62;ifType:&#60;/TD&#62;     &#60;TD&#62;ethernetCsmacd
(6)&#60;/TD&#62;&#60;/TR&#62;
   &#60;TR&#62;&#60;TD&#62;ifName:&#60;TD&#62;     &#60;TD&#62;&#60;/TD&#62;&#60;/TR&#62;
   &#60;TR&#62;&#60;TD&#62;Max Speed:&#60;/TD&#62;  &#60;TD&#62;1250.0
kBytes/s&#60;/TD&#62;&#60;/TR&#62;
   &#60;TR&#62;&#60;TD&#62;Ip:&#60;/TD&#62;         &#60;TD&#62;192.168.1.175
()&#60;/TD&#62;&#60;/TR&#62;
 &#60;/TABLE&#62;</PRE
></FONT
></TD
></TR
></TABLE
><P
>        All the configuration information has been pulled from
	<SPAN
CLASS="APPLICATION"
>snmpd</SPAN
>.  You can redirect the output
	of <B
CLASS="COMMAND"
>cfgmaker</B
> into
	<TT
CLASS="FILENAME"
>/etc/mrtg.cfg</TT
>.
      </P
><P
>        Most installations of <SPAN
CLASS="APPLICATION"
>mrtg</SPAN
> will
	include a <SPAN
CLASS="APPLICATION"
>cron</SPAN
> process to run
	<B
CLASS="COMMAND"
>mrtg</B
> if <TT
CLASS="FILENAME"
>/etc/mrtg.cfg</TT
>
	exists every five minutes.  Within five minutes,
	you will see data on your web site.
      </P
></DIV
></DIV
></DIV
><DIV
CLASS="CHAPTER"
><HR><H1
><A
NAME="KERNEL"
></A
>Chapter 6. Kernel Tuning</H1
><P
>    Unlike most other UNIX or UNIX-like operating systems, the source
    code to the kernel is available for easy tuning and upgrading.
    With kernels being packaged in distributions, the necessity for most
    users to compile their own kernels is pretty low.  There are advantages
    to compiling your own kernels, though:
  </P
><P
></P
><UL
><LI
><P
>        Compile a version of the kernel specific to your chipset.
      </P
></LI
><LI
><P
>        Add in a new driver or security patch
      </P
></LI
><LI
><P
>        Compile a kernel with modules compiled into the kernel
      </P
></LI
></UL
><P
>    This chapter covers each of these situations, and also tuning of running
    kernels using applications like <SPAN
CLASS="APPLICATION"
>sysconf</SPAN
> and
    <SPAN
CLASS="APPLICATION"
>powertweak</SPAN
>.
  </P
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="KERNELVERSIONS"
>6.1. Kernel versions</A
></H2
><P
>      There are a few things to consider when deciding what kernel revision
      you should be using in a production environment.
    </P
><P
>      Officially, Linux has two major threads of development.  The stable
      releases have an even number as its minor number.  The Linux 2.2 and 2.4
      kernels are examples of stable releases.  These are considered by Linus to
      be stable enough for production use.  Few known bugs or issues exist with
      these kernels.
    </P
><P
>      The other release is the development releases.  These have experimental
      drivers or changes to them, and can cause crashes if used in production
      environments.  However, these releases will be more likely to support
      newer hardware.
    </P
><P
>      Most Linux distributions will often make a compromise between stability
      and performance by creating their own version of the kernel and source
      code.  These kernels start with a base of a stable kernel, then add in
      some newer drivers.  The resulting kernel is then tested to make sure it
      is stable, then released.
    </P
><P
>      As a generalization, stable kernels are good for production use, while
      development kernels may have better performance.  For your use, you should
      monitor the changes in the two sets of kernels and see if there are any
      performance increases that will make your system faster, then test that
      against a known stable kernel.  You can then make a determination of
      stability of the system versus performance.
    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="KERNELCOMPILE"
>6.2. Compiling the Linux Kernel</A
></H2
><P
>      There is a specific order to getting your kernel compiled, and there
      is nothing preventing you from having multiple kernels and modules
      on the same system.  This allows you to boot test kernels while keeping
      a known stable kernel in case you have trouble.  Boot loaders like LILO
      will allow you to select a kernel at bootup.
    </P
><P
>      The easiest place to pick up the latest kernels is <A
HREF="http://www.kernel.org"
TARGET="_top"
>http://www.kernel.org</A
>.  This is
      the official site for Linux kernels.  These kernels are almost always
      in tar-bzip2 format, instead of being in RPM or DEB formats.  Check with
      your distribution provider for packaged formats of the kernel.
    </P
><P
>      Unpack and untar the kernel.  For packages compressed with bzip2,
      the process is:
    </P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
># tar -jxvf linux-2.2.19.tar.bz2</PRE
></FONT
></TD
></TR
></TABLE
><P
>      This will create all the header files and source code for the
      kernel.  There are three methods for configuring the kernel to compile,
      and each have some prerequisites.  All methods will obviously require
      the C compiler.
    </P
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="KERNELCOMPILECONFIG"
>6.2.1. Using <B
CLASS="COMMAND"
>make config</B
></A
></H3
><P
>        The siplest way (and the first) is to use <B
CLASS="COMMAND"
>make config</B
>
	from within <TT
CLASS="FILENAME"
>/usr/src/linux</TT
>.  This is a very
	tedious way of compiling, since you must answer each question
	and the Linux kernel has a large number of questions now.
      </P
><P
>        But an advantage to <B
CLASS="COMMAND"
>make config</B
> is that it
	does not require any other development tools to be installed
	in order to use it.  On very lightweight systems, using this
	method will save drive space and memory, since we are not
	running very complicated or large programs.
      </P
><P
>        SCREENSHOT OF make config HERE
      </P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="KERNELCOMPILEMENUCONFIG"
>6.2.2. Using <B
CLASS="COMMAND"
>make menuconfig</B
></A
></H3
><P
>        The next level of kernel configuration involves using a character
        based menuing system.  For systems that have only a text console
        or <SPAN
CLASS="APPLICATION"
>ssh</SPAN
> access, this makes an easier way
        to configure a kernel.  It requires both ncurses and its development
        libraries to be installed in order for this to work.  The program
        that runs in <B
CLASS="COMMAND"
>make menuconfig</B
> is part of the
        kernel source package and is compiled when needed.
      </P
><P
>        With an on-screen menu, it is easier to organize and select the
        options you want to compile in.  Help menus are available as well.
        This option is not good for those who want small systems, since it
        requires extra libraries.
      </P
><P
>        INSERT SCREENSHOT OF make menuconfig
      </P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="KERNELCOMPILEXCONFIG"
>6.2.3. Using <B
CLASS="COMMAND"
>make xconfig</B
></A
></H3
><P
>        The most user friendly, but hardest to use, is the <B
CLASS="COMMAND"
>make
	xconfig</B
> option for configuring the kernel.  This
	requires most of the X libraries to be installed, along with
	Tcl and Tk.
      </P
><P
>        Since many server systems may not have X or its associated libraries,
	Tcl, or Tk installed, you may want to step back to one of the other
	methods of configuring the kernel.  You would also need to make sure
	that you can export X to your desktop if you are configuring
	a remote system.
      </P
><DIV
CLASS="FIGURE"
><A
NAME="KERNELMAKEXCONFIG"
></A
><P
><B
>Figure 6-1. <B
CLASS="COMMAND"
>make xconfig</B
></B
></P
><DIV
CLASS="MEDIAOBJECT"
><P
><IMG
SRC="makexconfig.jpg"></P
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="KERNELCOMPILEOPTIONS"
>6.2.4. Options for configuring the kernel</A
></H3
><P
>        Now that you have chosen a way to configure the kernel, how
        should you go about your configuration?  What options should you
        pick for best performance, lowest memory consumption, and
        best security options?
      </P
><P
>        Many of the answers to these questions depends on your particular
        situation.  Selecting the right processor family for your CPI
        is one of the best things to do.  Each processor family has its
        own way of alinging memory and some CPU-specific options and
        optimizations.
      </P
><P
>        If your hardware setup is going to be stable, you can
	compile in drivers for various kinds of hardware for
	slightly better performance, and to prevent trojan
	modules from being loaded.  See <A
HREF="#KERNELCOMPILEOPTIONS"
>Section 6.2.4</A
>
	for more on this.
      </P
><P
>        Selecting DMA access for IDE devices under <SPAN
CLASS="QUOTE"
>"Block devices"</SPAN
>
	will automatically turn on DMA access, reducing CPU load.  You can see
	<A
HREF="#DISKTUNINGIDEOS"
>Section 4.3.1.2</A
> for more information.
      </P
><P
>        If your box will be configured as a router without firewalling,
	you can enable <SPAN
CLASS="QUOTE"
>"IP:  optimize as router not host"</SPAN
> under
	<SPAN
CLASS="QUOTE"
>"Networking options"</SPAN
>.  This reduces the latency of
	packets within the kernel by skipping a few unnecessary steps.
	But these steps are required if you will be doing firewalling
	or acting as a server.
      </P
><P
>        Bonding device support under <SPAN
CLASS="QUOTE"
>"Network device support"</SPAN
>
	will enable bonding multiple network devices together to create
	one large pipe to other bonded Linux boxes or some Cisco routers.
      </P
><P
>        If you plan on having a large number of users logging in and you would
	need a large number of pseudo terminals (PTYs), you can enter
	a number in <SPAN
CLASS="QUOTE"
>"Maximum number of Unix98 PTYs in use (0-2048)"</SPAN
>
	under <SPAN
CLASS="QUOTE"
>"Character devices"</SPAN
>.
      </P
><P
>        For systems that will not be onsite and require high availability,
	you can enable <SPAN
CLASS="QUOTE"
>"watchdog timer support"</SPAN
>.  Watchdogs
	can be implemented either in software or hardware.  Software watchdogs
	open and close files to make sure that everything is working.  If the
	driver cannot open the file, it tries to trigger a reboot of the system,
	since this indicates that there is some error with the system.
	Watchdog timers are usually implemented ISA cards, but some
	single board computers will have the necessary chips built in.  Hardware
	watchdogs are a bit better as it can monitor extra features such
	as temperature and fan speed and can trigger reboots on those events as
	well.  Hardware watchdogs are a bit more proactive as they continually
	talk to the kernel driver.  If the kernel driver does not respond,
	the watchdog triggers a reset.
      </P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="KERNELCOMPILEMODULES"
>6.2.5. Kernel Modules and You</A
></H3
><P
>        While this book is not specifically covering security, it is
	fair to bring it up every now and then.  For those who want
	hard core, as-uncrackable-as-possible systems, you may want
	to consider removing module support from your system.
      </P
><P
>        The reason for this is that if a cracker were to gain access
	to your system, one of the more advanced methods of covering their
	tracks is to insert a kernel module that hides much of their activity.
      </P
><P
>        Another tactic is to replace an existing module with a trojan horse.
	Once the module is loaded, its payload deploys in kernel space instead
	of userspace, giving the rogue code more access to the system.
      </P
><P
>        Another reason to remove modules from your system is to create a smaller
	size kernel.  With modules compiled into the kernel, they get
	compressed along with the rest of the kernel using bzip2.  Normally
	module files are uncompressed, but bzip2 can compress sizes by
	more than half.  This can save crucial space if it is required.
      </P
><P
>        For most users, however, you will want to use modules, as it gives a
	very versitile way of installing new drivers by just loading
	the module.
      </P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="KERNELCOMPILEBUILD"
>6.2.6. Building The Kernel</A
></H3
><P
>        With a configured kernel, you can now go through the build process.
	This is documented in a number of places, but it is included
	here for completeness.
      </P
><P
>        The first thing you should take a look at if you want to store the
	kernel configuration is to get
	<TT
CLASS="FILENAME"
>/usr/src/linux/.config</TT
>, as it has the ouput
	from the configuration options selected previously.  You can
	move the .config file to a new system, then build the kernel
	and skip the configuration part.
      </P
><P
>        The <B
CLASS="COMMAND"
>make dep</B
> command sets up the dependencies needed
	so the kernel can be built.  This is a crucial step, as the kernel
	will not compile without it.
      </P
><P
>        Most users will want to use <SPAN
CLASS="APPLICATION"
>bzip2</SPAN
> for
	building the kernel, as it makes a much smaller kernel than
	<SPAN
CLASS="APPLICATION"
>gzip</SPAN
> or uncompressed.  You can build a
	<SPAN
CLASS="APPLICATION"
>bzip2</SPAN
> kernel by using <B
CLASS="COMMAND"
>make
	bzImage</B
>.  The compressed image is built and put into <TT
CLASS="FILENAME"
>/usr/src/linux/arch/i386/</TT
>.
	You may want to just use <B
CLASS="COMMAND"
>make bzlilo</B
> to put the
	kernel into <TT
CLASS="FILENAME"
>/</TT
> and run
	<B
CLASS="COMMAND"
>lilo</B
> to let you boot the new kernel.
        Some users may not want their kernel in <TT
CLASS="FILENAME"
>/</TT
>, since many distributions create a small
	<TT
CLASS="FILENAME"
>/boot</TT
> partition that contains
	the kernel and enough to boot the kernel.  In this event, you will
	want to copy the kernel by and into <TT
CLASS="FILENAME"
>/boot</TT
>.
      </P
><P
>        If you will be using modules, you will also need to run <B
CLASS="COMMAND"
>make
	modules</B
> and <B
CLASS="COMMAND"
>make modules_install</B
>.  These
	two commands will build and install the modules for your kernel.
      </P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="KERNELRUNNING"
>6.3. Tuning a Runing Linux System</A
></H2
><P
>      When Linux first got started, changing options to the kernel often
      required recompiling.  Getting information out of Linux required
      applications be recompiled to look at the right memory location
      to get things like user and process lists.  After the release
      of the 1.0 kernel, the <TT
CLASS="FILENAME"
>/proc</TT
>
      filesystem arrived as a way to access information in a kernel-independent
      way.  Because of this, a command like <B
CLASS="COMMAND"
>ps</B
> will
      keep operating even if the kernel rev changes.  The <TT
CLASS="FILENAME"
>/proc</TT
> filesystem also allows you
      to change the kernel itself wile running, allowing you to add
      in features like TCP/IP forwarding, manage RAID cards, and so on.
    </P
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="KERNELRUNNINGPROC"
>6.3.1. The <TT
CLASS="FILENAME"
>/proc</TT
> filesystem</A
></H3
><P
>        This portion is not strictly about tuning a system, but getting
	information out of your urnning system.  In the event of serious
	memory or hardware issues, you can sometimes get information
	out of Linux.
      </P
><P
>        The <TT
CLASS="FILENAME"
>/proc</TT
> heirarchy may change
	depending on the kernel revision, but is generally arranged
	into different classes.
      </P
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
>Processes</DT
><DD
><P
>	      Contains information about each of the running processes,
	      organized by PID.  Each process has its own directory
	      of information, including status, list of file descriptors,
	      command line, environment variables for the application,
	      and working directory when the application was started.
	    </P
></DD
><DT
>bus</DT
><DD
><P
>	      Contains information about the system busses.  At this point,
	      it works with the USB, PCI, and PCMCIA busses.  More, like
	      IEEE-1394 will list devices and controllers under this directory.
	      The information about each device is less human readable than
	      older directoried like <TT
CLASS="FILENAME"
>/proc/pci
	      </TT
>, but human readability is not the point of
	      <TT
CLASS="FILENAME"
>/proc</TT
>
	    </P
></DD
><DT
>cpuinfo</DT
><DD
><P
>	      If you want to find out information about the CPU(s) installed in
	      your system, you can take a look at the cpuinfo file.  For each
	      processor, you will get things like CPU speed, vendor,
	      model type (Pentium II, Pentium III, etc.), and the
	      ever-popular bogomips rating.
	    </P
></DD
><DT
>filesystems</DT
><DD
><P
>	      This file has a list of the filesystems that the kernel currently
	      knows about.  We say currently, since modules can be loaded or
	      removed to add or remove additional filesystem types.  If
	      you are having trouble mounting a filesystem, this is an easy
	      way to make sure the filesystem type is supported by the kernel.
	    </P
></DD
><DT
>ide</DT
><DD
><P
>	      If your system has
	      
	      IDE devices, this directory contains information about the IDE
	      devices that are in your system.  It is organized by IDE
	      channels that are available, and each device has informaiton about
	      the model name and number, serial number, capacity, and any
	      other information specific to that IDE type.  Tuning of IDE
	      drives should be done using <B
CLASS="COMMAND"
>hdparm</B
>, and you can
	      see <A
HREF="#DISKTUNINGIDEOS"
>Section 4.3.1.2</A
> for usage.
	    </P
></DD
><DT
>meminfo</DT
><DD
><P
>	      This file has the raw memory information that you would normally
	      see as output of <B
CLASS="COMMAND"
>free</B
>.  The first
	      part of the ouput contains the memory listing in bytes, followed
	      by most of the same information in kilobytes.
	    </P
></DD
><DT
>modules</DT
><DD
><P
>	      You could easily mistake the contents of the modules file
	      for the output of <B
CLASS="COMMAND"
>lsmod</B
>.  There is a listing
	      of the modules, size of the module, and dependencies for
	      the module.
	    </P
></DD
><DT
>partitions</DT
><DD
><P
>	      This file has a list of all the disk partitions that are known
	      to Linux, including those not mounted or listed in <TT
CLASS="FILENAME"
>	      /etc/fstab</TT
>.
	    </P
></DD
><DT
>pci</DT
><DD
><P
>	      This file may go away in the long term, in favor of <TT
CLASS="FILENAME"
>/proc/bus/pci</TT
>, but <TT
CLASS="FILENAME"
>	      /proc/pci</TT
> is more human readable, listing
	      the device type, vendor, and device name.  But this
	      will only happen if the Linux kernel knows of the device.
	    </P
></DD
><DT
>scsi</DT
><DD
><P
>	      
	      SCSI-based systems can look at and tune their parameters here.
	      Its setup if much the same as for IDE, listing chains, followed by
	      devices on each chain.
	    </P
></DD
><DT
>swaps</DT
><DD
><P
>	      Lists all mounted swap partitions (or files) mounted.
	    </P
></DD
><DT
>version</DT
><DD
><P
>	      The version file contains version information of the kernel you
	      are using.  It's very helpful in that it has the user and host
	      that the kernel was compiled on, GCC version used to compile the
	      kernel, and date and time this kernel was compiled.  This
	      makes it much more helpful than <B
CLASS="COMMAND"
>uname</B
>, since
	      you can quickly check a series of running machines and verify
	      they all report the same kernel revision.
	    </P
></DD
></DL
></DIV
><P
>        Not listed above is <TT
CLASS="FILENAME"
>/proc/sys</TT
>.
	This directory is where most of the runtime changes to the kernel
	take place.  Access to this used to be done manually, using
	<B
CLASS="COMMAND"
>cat</B
> and <B
CLASS="COMMAND"
>echo</B
> to view or change
	settings of a running kernel.  If you wanted runtime settings to be
	changed each time the machine booted, you had to add commands to
	the <TT
CLASS="FILENAME"
>rc.local</TT
> file for each setting.
      </P
><P
>        An easier way to manage these settings is via the use of
	<B
CLASS="COMMAND"
>sysctl</B
>.
	
      </P
><P
><B
CLASS="COMMAND"
>sysctl</B
>  [-n] [<TT
CLASS="REPLACEABLE"
><I
>variable</I
></TT
>] [-w <TT
CLASS="REPLACEABLE"
><I
>variable</I
></TT
>=<TT
CLASS="REPLACEABLE"
><I
>value</I
></TT
>] [-a] [-p <TT
CLASS="REPLACEABLE"
><I
>filename</I
></TT
>]</P
><P
>        If you use an argument of <TT
CLASS="REPLACEABLE"
><I
>variable</I
></TT
>, you will
	get the current value of
	<TT
CLASS="FILENAME"
>/proc/sys/<TT
CLASS="REPLACEABLE"
><I
>variable</I
></TT
></TT
>.  You
	can set it by adding an equal sign and <TT
CLASS="REPLACEABLE"
><I
>value</I
></TT
>.
	You can get a list of what is available along with their current values
	by using -a.
      </P
><P
>        As part of the Linux boot sequence on more modern distributions,
	<B
CLASS="COMMAND"
>sysctl</B
> is called with -p, which reads
	settings from <TT
CLASS="FILENAME"
>/etc/sysctl.conf</TT
>.  This file can be
	edited by a text file, and contains a list of lines of the form
	<TT
CLASS="REPLACEABLE"
><I
>variable</I
></TT
>=<TT
CLASS="REPLACEABLE"
><I
>value</I
></TT
>.
      </P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="100%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>#
# /etc/sysctl.conf - Configuration file for setting system variables
# See sysctl.conf (5) for information.
#
#kernel.domainname = example.com
#net/ipv4/icmp_echo_ignore_broadcasts=1
net.ipv4.conf.all.hidden = 1
net.ipv4.conf.lo.hidden=1</PRE
></FONT
></TD
></TR
></TABLE
><P
>        As you can see, <TT
CLASS="REPLACEABLE"
><I
>variable</I
></TT
> can separate out
	directories using either a slash (/), or a dot (.).  Using the dot makes
	it look more like SNMP variables.
      </P
><P
>        Since everything under <TT
CLASS="FILENAME"
>/proc</TT
>
	are regular files, security for viewing or setting are handled by
	regular file permissions.  In some cases, only root can make changes,
	in others, only root can view or set.
      </P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="KERNELRUNNINGPOWERTWEAK"
>6.3.2. Using <B
CLASS="COMMAND"
>powertweak</B
></A
></H3
><P
>        Another interface to change options of a running kernel is through the
	use of <B
CLASS="COMMAND"
>powertweak</B
>.  Powertweak also runs on startup
	of linux, using a daemon called <SPAN
CLASS="APPLICATION"
>powertweakd</SPAN
>
	to issue changes to the kernel.  Configuration files are stored in the
	kernel in XML format.
      </P
><P
>        An advantage of using <B
CLASS="COMMAND"
>powertweak</B
> over
	<B
CLASS="COMMAND"
>sysctl</B
> is that powertweak has a graphical
	and text interface.  There is a pretty extensive help system that
	can give you information about each setting.
      </P
><P
>        For those that just want to have optimized settings for a particular
	use, there are pre-made settings for laptops, web servers, routers,
	and Oracle usage.  As an example, the laptop setting changes the kernel
	disk flush so the hard drive can spin down.  These are just generic
	settings, as each different machine has different PCI devices
	that can also be set.
      </P
><P
>        You can get the latest version of <SPAN
CLASS="APPLICATION"
>powertweak</SPAN
>
	from <A
HREF="http://www.powertweak.org/"
TARGET="_top"
>http://www.powertweak.org/</A
>
      </P
><DIV
CLASS="FIGURE"
><A
NAME="KERNELPOWERTWEAK"
></A
><P
><B
>Figure 6-2. Powertweak</B
></P
><DIV
CLASS="MEDIAOBJECT"
><P
><IMG
SRC="powertweak.jpg"></P
></DIV
></DIV
></DIV
></DIV
></DIV
><DIV
CLASS="CHAPTER"
><HR><H1
><A
NAME="APPS"
></A
>Chapter 7. Application Tuning</H1
><P
>    While one can tune hardware and the OS and get great measurements from it,
    most applications for Linux have their own rules for improving performance.
    Tuning a hard drive for an application that uses a lot of memory will not
    improve the speed of that application, whereas investing in more memory will
    create a vast improvement in speed.  Let us examine some of the applications
    for Linux and how you can tune a box specifically for it.
  </P
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="APPSSQUID"
>7.1. Squid Proxy Server</A
></H2
><P
>      Squid proxy server has two common uses.  The first is as a proxy 
      cache for internal clients access the external web.  The second is
      as a reverse proxy, caching content from internal web servers.
    </P
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="APPSSQUIDCACHE"
>7.1.1. Squid as a proxy cache</A
></H3
><P
>        Squid as a proxy cache stores large numbers of web pages, enabling
	them to be sent to clients upon request instead of requiring
	another internet fetch.  Squid uses large amounts of disk space
	for the cache, but by nature doesn't access any one that much more
	frequently than any other.
      </P
><P
>        The first thing to avoid is a disk bottleneck.  In a high-usage
	environment, you will definitely want to distribute the cache file
	across as many spindles as is practical.  Since the cache data is
	relatively worthless, in that it is flushed out as a matter of
	course, the additional overhead of a RAID 5 or other relatively
	fail-safe multi-spindle system is not necessary.  RAID 0 striping
	will provide the fastest access with no fail-safe requirements.
      </P
><P
>        The next thing to avoid is a memory bottleneck.  There should
	ABSOLUTELY be no OS paging with Squid, Squid will page enough on
	its own.  This is a case where Squid has in effect its own virtual
	memory system, with thousands of pages on disk and tens or
	hundreds in memory.  If the OS is paging to provide the tens or
	hundreds in memory, your performance will be horrible.
      </P
><P
>        Network performance will probably not be a big deal.  If your
	byte hit rate is 25%, and you are maxing out a T1, you are still
	only putting around 2Mbps out your Ethernet connection.
      </P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="AEN865"
>7.1.2. Squid as a reverse proxy</A
></H3
><P
>        As a reverse proxy, the total set of web pages that Squid is
	proxying is reduced greatly.  It must store only the limited
	number of pages behind it on your web servers, as opposed to
	the entire internet.  Since disk storage requirements are down
	by an order of magnitude, so are memory requirements.
      </P
><P
>	However, one approach to this situation would be to build up
	real memory until the entire working set of pages could be
	stored, with no paging required.
      </P
><P
>        In this case we're trading large store/infrequent access for a
	smaller store/frequent access.  We want to optimize the byte
	hit rate in Squid with real memory to reduce disk operations.
	Again, there should be NO OS PAGING.  If any DNS lookups are
	required, it might be a good idea to run a DNS cache locally.
	Otherwise, this shouldn't be too difficult to tune to get
	good performance.
      </P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="APPSMAIL"
>7.2. SMTP and Mail Delivery</A
></H2
><P
>      While this section addresses sendmail directly, most of the
      concepts should apply to any mail delivery system.
    </P
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="APPSMAILSENDMAIL"
>7.2.1. Sendmail</A
></H3
><P
>        
        A sendmail system will probably be the most likely to be
	network bottlenecked, but that bottleneck will also
	most likely be outside the system itself.  There are no
	special tricks since a typical sendmail system will be
	fairly balanced against typical hardware.  Depending
	on the size of the mail store, some type of RAID
	system may be implemented, but the mail store data
	is very valuable so use a RAID 5 or other fault-tolerant
	option.  If the store does get very large, you might
	also investigate the benefits of multiple caching
	layers down to the card.
      </P
><P
>        Sendmail itself is very dependent on DNS lookups for its
	operation, and may be doing ident lookups as well.  As such,
	some tricks on the network can really help.  Linux 2.4 kernels
	offer a lot of QoS features, these can be used to prioritize
	DNS and ident lookups over bulk traffic, preventing blocking
	of POP, IMAP, and SMTP waiting on a DNS lookup.  I would
	also strongly suggest implementing a DNS cache locally,
	maybe even on the sendmail server itself.
      </P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="APPSMAILDELIVERY"
>7.2.2. Mail Delivery (POP and IMAP)</A
></H3
><P
>	  
	  
	  Memory and processor requirements will depend on the number
	  of usersand whether you are providing POP or IMAP services,
	  or only SMTP.  POP and IMAP require logins, and each login
	  will spawn another POP or IMAP process.  If concurrent usage
	  of these services is high, watch for OS paging.
	</P
><P
>	  Using POP for delivery has a very low memory and hard drive
	  footprint.  In POP, e-mail is typically downloaded from the
	  server to the client.  The POP server merely handles authentication
	  and moving the data to the client.  When a mail message is sent
	  to the client, it is typically removed from the server.
	</P
><P
>	  Using IMAP puts much more stress on the system.  IMAP will copy
	  an entire mailbox into memory, and perform sorting and other
	  functions on the mailbox.  When a client requests a message, the
	  message is sent to the client, but is not removed from the server.
	  So all mail messages remain on the server until the client explicitly
	  deletes it.  The advantage to this is a user can have IMAP clients
	  on multiple machines and still be able to access all the messages.
	  Since most of the processing is offloaded to the server, this makes
	  IMAP a great mechanism for light clients or wireless devices
	  that do not have much memory or processing power.
	</P
><P
>	  Since the data on a POP or IMAP server are critical, you should
	  be using RAID-5 or RAID-1 to protect the data and keep
	  the server running.  POP has low memory requirements, while
	  IMAP has very high memory and disk requirements, and both
	  will likely increase as more users are introduced to the system
	  and they start working with mailboxes in the thousands of messages.
	</P
><P
>	  In either case, using SSL on top of POP or IMAP will also
	  increase the CPU load of the protocols, but will have minimal
	  affect on disk or memory usage.
	</P
><P
>	  It is not advisable
	  to put a shell account on the same machine as one running IMAP
	  or POP, due to the CPU and memory used by these protocols.
	  Nor is it advisable to use NFS to export a mailbox to a shell
	  machine, as NFS locks can cause corruption of a mailbox
	  if sendmail tries to deliver a message and the user is deleting
	  another message from the same mailbox.
	</P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="APPSDATABASE"
>7.3. MySQL, PostgresSQL, other databases</A
></H2
><P
></P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="APPSFIREWALL"
>7.4. Routers and firewalls</A
></H2
><P
></P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="APPSAPACHE"
>7.5. Apache web server</A
></H2
><P
>      Apache works best when it is delivering static content.  But if you're
      only delivering static content, you should consider using
      <SPAN
CLASS="APPLICATION"
>Tux</SPAN
>, the Linux kernel HTTP server.
    </P
><P
>      There are a number of small quick-tips you can use to increase the
      throughput and responsiveness of Apache.
    </P
><P
>      One such tip is to turn off DNS resolving in Apache.  When Apache receives
      a request to send data to a remote server, Apache will request a reverse
      DNS lookup on that IP address.  While the requests winds its way through
      the DNS heirarchy, Apache is stuck waiting for the answer before it can
      send the page back to the requesting client.  By turning this feature off,
      Apache will merely log the IP address without name in its log file, and
      then deliver the page.  A problem with this is if the machine is cracked
      through the web server, you will have to do your own reverse DNS lookup to
      find out what country and domain the machine is from.  A way to have the
      best of both worlds is to run a caching-only name server run on the local
      network or on the web server box itself.  This allows Apache to quickly
      get the DNS information, and store a hostname and domain instead of just
      an IP address.
    </P
><P
>      Cutting the size of graphic images is also a way to improve performance.
      Using algorithms such as JPG or PNM will cut the size of the image file
      without reducing the quality of the image by much.  This allows more image
      files to go out per second.
    </P
><P
>      Instead of reinventing the wheel, see if Apache has a module for the
      feature you need.  Modules for authentication against SMB, NIS, and LDAP
      servers all exist for Apache, and you will not have to add the
      functionality to your server side scripts.
    </P
><P
>      Make sure your database is tuned properly.  This has been covered in
      <A
HREF="#APPSDATABASE"
>Section 7.3</A
>, but a poorly tuned database can slow
      everything down.  If you expect heavy usage, do not put the database and
      web server on the same machine.  One machine running the database, and
      another running the web server connected by high speed (gigabit Ethernet)
      will allow both machines to operate quickly.
    </P
><P
>      Since so many web sites are using server-based applications and CGI, it
      makes sense to take a look at the server interpreters being used.  If you
      use a language like Java that is known to be pretty slow, you can expect
      lower performance as compared to using applications compiled in C.
    </P
><P
>      But Java has its own advantages over C.  The biggest is that Java is
      designed to be much more portable than C is.  Since Java is an object
      oriented language, its code reuse is much better, allowing delopers to
      create applications quicky.
    </P
><P
>      There are three other major server languages used by Apache.  These are
      Perl, Python, and PHP.  All three are included in most Linux
      distributions, and if they're not on your system, each is easy to install
      and get working.
    </P
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="APPSAPACHEPERL"
>7.5.1. Perl</A
></H3
><P
>        Perl is pretty much the granddaddy of CGI and server programs.  It has
	excellent string manipulation abilities, plenty of libraries to let you
	create web applications quickly, and has drivers for just about anything
	you want to do.  It is known as the programmer's swiss army knife, and
	for good reason.
      </P
><P
>        The downside to perl is that it is an interpreted language, meaning each
	time a perl application is run, the perl interpreter has to be loaded,
	the application has to be loaded into memory, and the interpreter has to
	compile the application.  This can create a heavy load on a system.
      </P
><P
>        
        The best way around this is to use the mod_perl library with
	<SPAN
CLASS="APPLICATION"
>apache</SPAN
>.  This library first loads the perl
	interpreter so it is always in memory and ready to run.  It also caches
	frequently-used perl CGI scripts in memory already in a precompiled
	state.  When a perl application starts up, many of the bottlenecks
	(loading and interpreting) have already been done.
        The cost to the sysadmin and programmer is that mod_perl takes up a lot
	of memory, and its memory use will increase as more perl scripts are
	added to a web server.
      </P
><DIV
CLASS="NOTE"
><P
></P
><TABLE
CLASS="NOTE"
WIDTH="100%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/note.png"
HSPACE="5"
ALT="Note"></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
><P
>	  Adding more memory and CPU speed to a machine running mod_perl will
	  improve its performance.
	</P
></TD
></TR
></TABLE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="APPSAPACHEPYTHON"
>7.5.2. Python</A
></H3
><P
>        Python was one of the first of the interpreted languages to implement
	object oriented programming, allowing programmers to reuse and share
	code.  It also learned a bit from perl and it's interpreted nature by
	comiling python code into a pre-compiled format.  This format is not
	portable like Java, but does much of the grunt work of compiling a
	python application.  The python interpreter then spends less time
	compiling the application each time it's run.
      </P
><P
>        Programmers may cringe a bit when they start writing in python.  Syntax
	is much more strict than C or Perl, using tabs and newlines to delineate
	parts of code.  And, like perl, python requires the interpreter to load
	into memory and run.
      </P
><P
>        There is also a mod_python for apache that operates simiar to mod_perl.
	More memory and CPU speed will be a great improvement.
      </P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="APPSAPACHEPHP"
>7.5.3. PHP</A
></H3
><P
>        PHP is a relative newcomer to the languages listed here.  But PHP was
	designed for server side applications.  The interpreter is a module in
	<SPAN
CLASS="APPLICATION"
>apache</SPAN
>, and PHP code can exist within a HTML
	page, allowing authors to combine the web page and application into one
	file.
      </P
><P
>        PHP has two downsides to it from a programer's perspective.  First, PHP
	is still relatively new.  It is not quite as seasoned as Perl or Python,
	each of which have over ten years worth of development behind them.
	Second, PHP does not have modules that can be easily loaded and used
	like Perl and Python have.  If your implementation of PHP does not have
	the graphics libraries installes, you will have to recompile PHP and add
	them in.  Neither of these should prevent you from giving a serious look
	at using PHP for your server side application.
      </P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="APPSSAMBA"
>7.6. Samba File Sharing</A
></H2
><P
></P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="APPSNFS"
>7.7. Network File System</A
></H2
><P
></P
></DIV
></DIV
></DIV
></BODY
></HTML
>